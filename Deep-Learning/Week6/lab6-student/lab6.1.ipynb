{"cells":[{"cell_type":"markdown","metadata":{"id":"ipXgbahwzFwE"},"source":["# Lab 6.1 - MNIST MLP with PyTorch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eUk406zEzFwK"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from sklearn.model_selection import GridSearchCV\n","from skorch import NeuralNetClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1683172962710,"user":{"displayName":"Timo Wang","userId":"08366322370343653096"},"user_tz":300},"id":"1CJ9omvPzFwL","outputId":"d7166180-7319-4b72-cc74-43f5e969225e"},"outputs":[{"data":{"text/plain":["\u003ctorch._C.Generator at 0x7f8435e3f230\u003e"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["torch.random.manual_seed(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qFyyzOyjzFwL"},"outputs":[],"source":["# Define the neural network\n","class MLP(nn.Module):\n","    def __init__(self, num_layers=10, num_units=128, dropout=0.5):\n","        super(MLP, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.input_layer = nn.Linear(28*28, num_units)\n","        self.relu = nn.ReLU()\n","        self.hidden_layers = nn.ModuleList(\n","            [nn.Linear(num_units, num_units) for _ in range(num_layers)])\n","        self.output_layer = nn.Linear(num_units, 10)\n","        self.dropout = nn.Dropout(dropout)\n","\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.input_layer(x)\n","        x = self.relu(x)\n","        for hidden_layer in self.hidden_layers:\n","            x = hidden_layer(x)\n","            x = self.relu(x)\n","            x = self.dropout(x)\n","        x = self.output_layer(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ypOTHFvRzFwM"},"outputs":[],"source":["# Load the MNIST dataset\n","transform = transforms.Compose(\n","    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","trainset = torchvision.datasets.MNIST(\n","    root=\"./data\", train=True, download=True, transform=transform)\n","\n","testset = torchvision.datasets.MNIST(\n","    root=\"./data\", train=False, download=True, transform=transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1683172963276,"user":{"displayName":"Timo Wang","userId":"08366322370343653096"},"user_tz":300},"id":"sGujyjXezFwM","outputId":"877fa016-2315-46cc-e73e-7fd43b99a863"},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train.shape torch.Size([60000, 28, 28])\n","y_train.shape torch.Size([60000])\n","X_train.dtype torch.float32\n","y_train.dtype torch.int64\n"]}],"source":["# Convert trainset and testset to numpy arrays\n","X_train = trainset.data.numpy()\n","y_train = trainset.targets.numpy()\n","X_test = testset.data.numpy()\n","y_test = testset.targets.numpy()\n","\n","# Convert numpy arrays to tensors\n","X_train = torch.from_numpy(X_train).to(torch.float)\n","y_train = torch.from_numpy(y_train)\n","X_test = torch.from_numpy(X_test).to(torch.float)\n","y_test = torch.from_numpy(y_test)\n","\n","print(\"X_train.shape\", X_train.shape)\n","print(\"y_train.shape\", y_train.shape)\n","print(\"X_train.dtype\", X_train.dtype)\n","print(\"y_train.dtype\", y_train.dtype)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1683172963276,"user":{"displayName":"Timo Wang","userId":"08366322370343653096"},"user_tz":300},"id":"oEeanIVOzFwN","outputId":"d2ed5450-428f-44b1-ec7f-cacfb633ec9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Labels {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"]}],"source":["print(\"Labels\", set(y_train.numpy()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CbZu2DK4zFwN"},"outputs":[],"source":["# Wrap the MLP into a scikit-learn classifier\n","mlp = MLP()\n","# mlp.to(torch.device(\"cuda\"))\n","model = NeuralNetClassifier(\n","    mlp,\n","    max_epochs=50,\n","    lr=0.001,\n","    optimizer=optim.Adam,\n","    criterion=nn.CrossEntropyLoss,\n","    verbose=True,\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"5sr2BnMZzFwO"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 8 candidates, totalling 24 fits\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.4395\u001b[0m       \u001b[32m0.6560\u001b[0m        \u001b[35m1.4228\u001b[0m  2.1830\n","      2        \u001b[36m1.4204\u001b[0m       \u001b[32m0.8241\u001b[0m        \u001b[35m0.6592\u001b[0m  1.8642\n","      3        \u001b[36m0.9120\u001b[0m       \u001b[32m0.8819\u001b[0m        \u001b[35m0.4254\u001b[0m  1.8654\n","      4        \u001b[36m0.6820\u001b[0m       \u001b[32m0.9042\u001b[0m        \u001b[35m0.3386\u001b[0m  1.9449\n","      5        \u001b[36m0.5499\u001b[0m       \u001b[32m0.9181\u001b[0m        \u001b[35m0.2905\u001b[0m  1.9649\n","      6        \u001b[36m0.4588\u001b[0m       \u001b[32m0.9273\u001b[0m        \u001b[35m0.2652\u001b[0m  2.5458\n","      7        \u001b[36m0.3903\u001b[0m       \u001b[32m0.9323\u001b[0m        \u001b[35m0.2465\u001b[0m  1.9108\n","      8        \u001b[36m0.3475\u001b[0m       \u001b[32m0.9387\u001b[0m        \u001b[35m0.2281\u001b[0m  1.9108\n","      9        \u001b[36m0.3149\u001b[0m       \u001b[32m0.9431\u001b[0m        \u001b[35m0.2190\u001b[0m  2.8152\n","     10        \u001b[36m0.2740\u001b[0m       \u001b[32m0.9446\u001b[0m        \u001b[35m0.2139\u001b[0m  2.1997\n","     11        \u001b[36m0.2501\u001b[0m       \u001b[32m0.9496\u001b[0m        \u001b[35m0.1989\u001b[0m  3.4795\n","     12        \u001b[36m0.2279\u001b[0m       \u001b[32m0.9509\u001b[0m        \u001b[35m0.1932\u001b[0m  2.4945\n","     13        \u001b[36m0.2102\u001b[0m       \u001b[32m0.9511\u001b[0m        \u001b[35m0.1901\u001b[0m  1.9170\n","     14        \u001b[36m0.1943\u001b[0m       \u001b[32m0.9535\u001b[0m        \u001b[35m0.1882\u001b[0m  1.8958\n","     15        \u001b[36m0.1763\u001b[0m       \u001b[32m0.9543\u001b[0m        \u001b[35m0.1866\u001b[0m  1.9047\n","     16        \u001b[36m0.1635\u001b[0m       \u001b[32m0.9547\u001b[0m        0.1878  1.9144\n","     17        \u001b[36m0.1522\u001b[0m       \u001b[32m0.9575\u001b[0m        \u001b[35m0.1748\u001b[0m  2.2917\n","     18        \u001b[36m0.1384\u001b[0m       \u001b[32m0.9586\u001b[0m        \u001b[35m0.1742\u001b[0m  2.1693\n","     19        \u001b[36m0.1293\u001b[0m       \u001b[32m0.9589\u001b[0m        0.1812  1.9047\n","     20        \u001b[36m0.1203\u001b[0m       \u001b[32m0.9605\u001b[0m        \u001b[35m0.1721\u001b[0m  1.9247\n","     21        \u001b[36m0.1134\u001b[0m       0.9600        0.1840  1.9386\n","     22        \u001b[36m0.1068\u001b[0m       \u001b[32m0.9613\u001b[0m        0.1755  1.9440\n","     23        \u001b[36m0.1014\u001b[0m       \u001b[32m0.9633\u001b[0m        0.1862  2.4577\n","     24        \u001b[36m0.0914\u001b[0m       0.9630        0.1730  1.9918\n","     25        \u001b[36m0.0849\u001b[0m       \u001b[32m0.9643\u001b[0m        0.1802  1.9441\n","     26        \u001b[36m0.0805\u001b[0m       0.9639        0.1830  1.9205\n","     27        \u001b[36m0.0752\u001b[0m       \u001b[32m0.9644\u001b[0m        0.1902  1.9157\n","     28        0.0766       0.9641        0.1790  1.9372\n","     29        \u001b[36m0.0658\u001b[0m       \u001b[32m0.9654\u001b[0m        0.1835  2.5550\n","     30        0.0660       \u001b[32m0.9660\u001b[0m        0.2042  1.9577\n","     31        \u001b[36m0.0623\u001b[0m       \u001b[32m0.9666\u001b[0m        0.1917  1.9845\n","     32        \u001b[36m0.0573\u001b[0m       0.9650        0.1977  1.9480\n","     33        0.0595       0.9657        0.1939  1.9499\n","     34        \u001b[36m0.0542\u001b[0m       \u001b[32m0.9680\u001b[0m        0.1890  1.9545\n","     35        \u001b[36m0.0484\u001b[0m       0.9663        0.2035  2.5677\n","     36        \u001b[36m0.0483\u001b[0m       0.9661        0.2062  1.9721\n","     37        \u001b[36m0.0459\u001b[0m       0.9676        0.2109  2.0393\n","     38        \u001b[36m0.0434\u001b[0m       \u001b[32m0.9681\u001b[0m        0.2013  2.0183\n","     39        \u001b[36m0.0432\u001b[0m       0.9661        0.2119  1.9860\n","     40        \u001b[36m0.0421\u001b[0m       0.9661        0.2156  2.3952\n","     41        \u001b[36m0.0370\u001b[0m       0.9674        0.2031  2.2115\n","     42        0.0373       \u001b[32m0.9689\u001b[0m        0.2147  1.9962\n","     43        \u001b[36m0.0354\u001b[0m       0.9679        0.2223  2.0254\n","     44        \u001b[36m0.0301\u001b[0m       0.9677        0.2121  1.9993\n","     45        0.0383       0.9684        0.2220  2.0032\n","     46        0.0328       0.9688        0.2181  2.5906\n","     47        \u001b[36m0.0297\u001b[0m       0.9681        0.2254  2.0167\n","     48        0.0333       0.9681        0.2226  2.0137\n","     49        \u001b[36m0.0256\u001b[0m       \u001b[32m0.9698\u001b[0m        0.2256  2.0525\n","     50        0.0262       0.9673        0.2283  2.0444\n","[CV] END lr=0.0001, max_epochs=50, module__num_layers=3, module__num_units=128; total time= 1.8min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.3698\u001b[0m       \u001b[32m0.5793\u001b[0m        \u001b[35m1.4890\u001b[0m  2.4375\n","      2        \u001b[36m1.4349\u001b[0m       \u001b[32m0.8295\u001b[0m        \u001b[35m0.6629\u001b[0m  1.8810\n","      3        \u001b[36m0.9187\u001b[0m       \u001b[32m0.8969\u001b[0m        \u001b[35m0.3970\u001b[0m  1.8347\n","      4        \u001b[36m0.6616\u001b[0m       \u001b[32m0.9171\u001b[0m        \u001b[35m0.3093\u001b[0m  1.8591\n","      5        \u001b[36m0.5284\u001b[0m       \u001b[32m0.9267\u001b[0m        \u001b[35m0.2657\u001b[0m  1.8833\n","      6        \u001b[36m0.4482\u001b[0m       \u001b[32m0.9353\u001b[0m        \u001b[35m0.2410\u001b[0m  1.8899\n","      7        \u001b[36m0.3915\u001b[0m       \u001b[32m0.9390\u001b[0m        \u001b[35m0.2239\u001b[0m  2.4438\n","      8        \u001b[36m0.3434\u001b[0m       \u001b[32m0.9419\u001b[0m        \u001b[35m0.2096\u001b[0m  1.9476\n","      9        \u001b[36m0.3147\u001b[0m       \u001b[32m0.9455\u001b[0m        \u001b[35m0.1966\u001b[0m  1.9047\n","     10        \u001b[36m0.2834\u001b[0m       \u001b[32m0.9500\u001b[0m        \u001b[35m0.1881\u001b[0m  1.8788\n","     11        \u001b[36m0.2572\u001b[0m       \u001b[32m0.9513\u001b[0m        \u001b[35m0.1855\u001b[0m  1.8913\n","     12        \u001b[36m0.2354\u001b[0m       \u001b[32m0.9549\u001b[0m        \u001b[35m0.1761\u001b[0m  1.9072\n","     13        \u001b[36m0.2203\u001b[0m       \u001b[32m0.9566\u001b[0m        \u001b[35m0.1665\u001b[0m  2.5605\n","     14        \u001b[36m0.2007\u001b[0m       \u001b[32m0.9589\u001b[0m        0.1680  1.9093\n","     15        \u001b[36m0.1868\u001b[0m       0.9574        0.1749  1.8859\n","     16        \u001b[36m0.1742\u001b[0m       \u001b[32m0.9595\u001b[0m        \u001b[35m0.1558\u001b[0m  1.9193\n","     17        \u001b[36m0.1619\u001b[0m       \u001b[32m0.9607\u001b[0m        0.1611  1.8876\n","     18        \u001b[36m0.1496\u001b[0m       \u001b[32m0.9621\u001b[0m        0.1612  1.9059\n","     19        \u001b[36m0.1388\u001b[0m       \u001b[32m0.9624\u001b[0m        0.1578  2.5081\n","     20        \u001b[36m0.1337\u001b[0m       \u001b[32m0.9625\u001b[0m        0.1631  1.9137\n","     21        \u001b[36m0.1250\u001b[0m       \u001b[32m0.9637\u001b[0m        0.1567  1.9055\n","     22        \u001b[36m0.1132\u001b[0m       0.9630        0.1666  1.9006\n","     23        \u001b[36m0.1074\u001b[0m       \u001b[32m0.9650\u001b[0m        0.1612  1.9118\n","     24        \u001b[36m0.1031\u001b[0m       0.9647        0.1630  1.9175\n","     25        \u001b[36m0.0984\u001b[0m       0.9637        0.1599  2.5431\n","     26        \u001b[36m0.0930\u001b[0m       0.9649        \u001b[35m0.1528\u001b[0m  1.9244\n","     27        \u001b[36m0.0858\u001b[0m       \u001b[32m0.9675\u001b[0m        0.1630  1.8949\n","     28        \u001b[36m0.0828\u001b[0m       \u001b[32m0.9680\u001b[0m        0.1700  1.9134\n","     29        \u001b[36m0.0776\u001b[0m       0.9651        0.1759  1.9207\n","     30        0.0789       0.9676        0.1630  2.0067\n","     31        \u001b[36m0.0678\u001b[0m       0.9651        0.1758  2.4698\n","     32        0.0698       \u001b[32m0.9689\u001b[0m        0.1647  1.9469\n","     33        \u001b[36m0.0633\u001b[0m       0.9659        0.1778  1.9378\n","     34        \u001b[36m0.0591\u001b[0m       \u001b[32m0.9690\u001b[0m        0.1811  1.9516\n","     35        0.0631       \u001b[32m0.9696\u001b[0m        0.1664  1.9431\n","     36        \u001b[36m0.0567\u001b[0m       0.9675        0.1863  2.2528\n","     37        \u001b[36m0.0512\u001b[0m       0.9688        0.1804  2.2752\n","     38        \u001b[36m0.0475\u001b[0m       0.9677        0.1831  1.9857\n","     39        \u001b[36m0.0471\u001b[0m       \u001b[32m0.9705\u001b[0m        0.1716  1.9625\n","     40        \u001b[36m0.0468\u001b[0m       0.9695        0.1990  1.9573\n","     41        0.0471       0.9677        0.1877  1.9653\n","     42        \u001b[36m0.0421\u001b[0m       0.9683        0.2051  2.6058\n","     43        \u001b[36m0.0408\u001b[0m       0.9659        0.2248  2.0050\n","     44        0.0428       0.9701        0.1869  2.0037\n","     45        0.0422       0.9691        0.2004  2.0176\n","     46        \u001b[36m0.0397\u001b[0m       0.9692        0.2038  2.0301\n","     47        \u001b[36m0.0383\u001b[0m       0.9677        0.2128  2.1117\n","     48        \u001b[36m0.0371\u001b[0m       0.9689        0.2159  2.5481\n","     49        0.0392       0.9699        0.2001  2.0325\n","     50        \u001b[36m0.0280\u001b[0m       0.9698        0.2057  2.0440\n","[CV] END lr=0.0001, max_epochs=50, module__num_layers=3, module__num_units=128; total time= 1.7min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.4862\u001b[0m       \u001b[32m0.5873\u001b[0m        \u001b[35m1.6650\u001b[0m  1.8316\n","      2        \u001b[36m1.5898\u001b[0m       \u001b[32m0.7568\u001b[0m        \u001b[35m0.8487\u001b[0m  1.8182\n","      3        \u001b[36m1.0707\u001b[0m       \u001b[32m0.8491\u001b[0m        \u001b[35m0.5521\u001b[0m  2.4246\n","      4        \u001b[36m0.8007\u001b[0m       \u001b[32m0.8952\u001b[0m        \u001b[35m0.3907\u001b[0m  1.8722\n","      5        \u001b[36m0.6236\u001b[0m       \u001b[32m0.9175\u001b[0m        \u001b[35m0.3086\u001b[0m  1.8754\n","      6        \u001b[36m0.5174\u001b[0m       \u001b[32m0.9296\u001b[0m        \u001b[35m0.2594\u001b[0m  1.8874\n","      7        \u001b[36m0.4414\u001b[0m       \u001b[32m0.9390\u001b[0m        \u001b[35m0.2316\u001b[0m  1.9197\n","      8        \u001b[36m0.3848\u001b[0m       \u001b[32m0.9463\u001b[0m        \u001b[35m0.2121\u001b[0m  1.9054\n","      9        \u001b[36m0.3418\u001b[0m       \u001b[32m0.9495\u001b[0m        \u001b[35m0.1962\u001b[0m  2.5040\n","     10        \u001b[36m0.3022\u001b[0m       \u001b[32m0.9536\u001b[0m        \u001b[35m0.1820\u001b[0m  1.9280\n","     11        \u001b[36m0.2758\u001b[0m       \u001b[32m0.9559\u001b[0m        \u001b[35m0.1739\u001b[0m  1.9066\n","     12        \u001b[36m0.2470\u001b[0m       \u001b[32m0.9569\u001b[0m        \u001b[35m0.1663\u001b[0m  1.9088\n","     13        \u001b[36m0.2262\u001b[0m       \u001b[32m0.9574\u001b[0m        0.1671  1.9437\n","     14        \u001b[36m0.2185\u001b[0m       \u001b[32m0.9604\u001b[0m        \u001b[35m0.1578\u001b[0m  1.9173\n","     15        \u001b[36m0.1924\u001b[0m       \u001b[32m0.9621\u001b[0m        \u001b[35m0.1563\u001b[0m  2.5182\n","     16        \u001b[36m0.1787\u001b[0m       0.9617        \u001b[35m0.1525\u001b[0m  1.9196\n","     17        \u001b[36m0.1706\u001b[0m       \u001b[32m0.9629\u001b[0m        \u001b[35m0.1514\u001b[0m  1.9347\n","     18        \u001b[36m0.1562\u001b[0m       \u001b[32m0.9635\u001b[0m        \u001b[35m0.1471\u001b[0m  1.9285\n","     19        \u001b[36m0.1441\u001b[0m       0.9634        0.1488  1.9285\n","     20        \u001b[36m0.1302\u001b[0m       \u001b[32m0.9665\u001b[0m        \u001b[35m0.1460\u001b[0m  1.9621\n","     21        \u001b[36m0.1289\u001b[0m       \u001b[32m0.9669\u001b[0m        0.1479  2.5025\n","     22        \u001b[36m0.1158\u001b[0m       0.9657        \u001b[35m0.1437\u001b[0m  1.9470\n","     23        \u001b[36m0.1109\u001b[0m       \u001b[32m0.9671\u001b[0m        0.1443  1.9366\n","     24        \u001b[36m0.1042\u001b[0m       0.9666        0.1440  1.9252\n","     25        \u001b[36m0.0998\u001b[0m       \u001b[32m0.9680\u001b[0m        0.1516  1.9315\n","     26        \u001b[36m0.0986\u001b[0m       \u001b[32m0.9691\u001b[0m        0.1465  2.1885\n","     27        \u001b[36m0.0930\u001b[0m       0.9681        0.1571  2.2807\n","     28        \u001b[36m0.0835\u001b[0m       0.9680        0.1521  1.9245\n","     29        \u001b[36m0.0781\u001b[0m       0.9689        0.1535  1.9518\n","     30        \u001b[36m0.0771\u001b[0m       \u001b[32m0.9699\u001b[0m        0.1512  1.9278\n","     31        \u001b[36m0.0747\u001b[0m       \u001b[32m0.9706\u001b[0m        0.1574  1.9261\n","     32        \u001b[36m0.0678\u001b[0m       \u001b[32m0.9710\u001b[0m        0.1566  2.3915\n","     33        \u001b[36m0.0635\u001b[0m       0.9688        0.1666  2.1152\n","     34        \u001b[36m0.0614\u001b[0m       \u001b[32m0.9724\u001b[0m        0.1564  1.9563\n","     35        0.0625       0.9705        0.1564  1.9638\n","     36        \u001b[36m0.0567\u001b[0m       \u001b[32m0.9725\u001b[0m        0.1621  1.9870\n","     37        \u001b[36m0.0513\u001b[0m       0.9722        0.1624  1.9929\n","     38        0.0518       0.9710        0.1757  2.5989\n","     39        \u001b[36m0.0499\u001b[0m       0.9718        0.1640  1.9901\n","     40        \u001b[36m0.0490\u001b[0m       0.9714        0.1611  1.9987\n","     41        \u001b[36m0.0465\u001b[0m       0.9720        0.1632  1.9814\n","     42        0.0480       0.9712        0.1753  2.0041\n","     43        \u001b[36m0.0432\u001b[0m       0.9721        0.1705  2.2110\n","     44        \u001b[36m0.0394\u001b[0m       0.9718        0.1707  2.4562\n","     45        0.0405       0.9719        0.1870  2.0145\n","     46        \u001b[36m0.0360\u001b[0m       \u001b[32m0.9726\u001b[0m        0.1912  2.0184\n","     47        0.0378       \u001b[32m0.9741\u001b[0m        0.1677  2.0184\n","     48        \u001b[36m0.0322\u001b[0m       0.9722        0.1946  2.0311\n","     49        0.0346       0.9729        0.1904  2.6501\n","     50        \u001b[36m0.0317\u001b[0m       0.9734        0.1865  2.0716\n","[CV] END lr=0.0001, max_epochs=50, module__num_layers=3, module__num_units=128; total time= 1.7min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m1.9844\u001b[0m       \u001b[32m0.8066\u001b[0m        \u001b[35m0.6814\u001b[0m  3.1115\n","      2        \u001b[36m0.8155\u001b[0m       \u001b[32m0.8952\u001b[0m        \u001b[35m0.3572\u001b[0m  3.1012\n","      3        \u001b[36m0.5225\u001b[0m       \u001b[32m0.9210\u001b[0m        \u001b[35m0.2748\u001b[0m  3.7340\n","      4        \u001b[36m0.3910\u001b[0m       \u001b[32m0.9330\u001b[0m        \u001b[35m0.2369\u001b[0m  3.1265\n","      5        \u001b[36m0.3146\u001b[0m       \u001b[32m0.9420\u001b[0m        \u001b[35m0.2036\u001b[0m  3.1492\n","      6        \u001b[36m0.2663\u001b[0m       \u001b[32m0.9480\u001b[0m        \u001b[35m0.1842\u001b[0m  3.3450\n","      7        \u001b[36m0.2280\u001b[0m       \u001b[32m0.9534\u001b[0m        \u001b[35m0.1757\u001b[0m  3.6169\n","      8        \u001b[36m0.1986\u001b[0m       \u001b[32m0.9557\u001b[0m        \u001b[35m0.1638\u001b[0m  3.1581\n","      9        \u001b[36m0.1796\u001b[0m       \u001b[32m0.9593\u001b[0m        \u001b[35m0.1547\u001b[0m  3.1448\n","     10        \u001b[36m0.1582\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1454\u001b[0m  3.7950\n","     11        \u001b[36m0.1443\u001b[0m       \u001b[32m0.9636\u001b[0m        \u001b[35m0.1419\u001b[0m  3.1872\n","     12        \u001b[36m0.1243\u001b[0m       \u001b[32m0.9643\u001b[0m        0.1429  3.1758\n","     13        \u001b[36m0.1164\u001b[0m       \u001b[32m0.9651\u001b[0m        \u001b[35m0.1362\u001b[0m  3.1777\n","     14        \u001b[36m0.1005\u001b[0m       \u001b[32m0.9664\u001b[0m        0.1364  3.8182\n","     15        \u001b[36m0.0887\u001b[0m       0.9659        \u001b[35m0.1351\u001b[0m  3.1900\n","     16        \u001b[36m0.0816\u001b[0m       0.9661        0.1424  3.1909\n","     17        \u001b[36m0.0791\u001b[0m       \u001b[32m0.9685\u001b[0m        \u001b[35m0.1348\u001b[0m  3.8472\n","     18        \u001b[36m0.0698\u001b[0m       0.9674        0.1426  3.2004\n","     19        \u001b[36m0.0623\u001b[0m       \u001b[32m0.9700\u001b[0m        0.1427  3.2142\n","     20        \u001b[36m0.0613\u001b[0m       \u001b[32m0.9706\u001b[0m        \u001b[35m0.1347\u001b[0m  3.2246\n","     21        \u001b[36m0.0513\u001b[0m       0.9705        0.1453  3.8593\n","     22        \u001b[36m0.0490\u001b[0m       0.9685        0.1546  3.1979\n","     23        \u001b[36m0.0466\u001b[0m       \u001b[32m0.9714\u001b[0m        0.1473  3.2001\n","     24        \u001b[36m0.0431\u001b[0m       \u001b[32m0.9722\u001b[0m        0.1553  3.8547\n","     25        \u001b[36m0.0395\u001b[0m       0.9698        0.1531  3.2341\n","     26        \u001b[36m0.0337\u001b[0m       0.9716        0.1570  3.2196\n","     27        \u001b[36m0.0327\u001b[0m       0.9709        0.1619  3.3147\n","     28        \u001b[36m0.0302\u001b[0m       0.9710        0.1672  3.8988\n","     29        0.0313       \u001b[32m0.9726\u001b[0m        0.1664  3.2969\n","     30        \u001b[36m0.0297\u001b[0m       0.9726        0.1707  3.2698\n","     31        \u001b[36m0.0254\u001b[0m       \u001b[32m0.9738\u001b[0m        0.1669  3.9102\n","     32        0.0260       0.9736        0.1737  3.3509\n","     33        \u001b[36m0.0232\u001b[0m       0.9704        0.2006  3.3399\n","     34        0.0275       0.9725        0.1689  3.7062\n","     35        0.0243       0.9704        0.1843  3.5954\n","     36        \u001b[36m0.0188\u001b[0m       0.9704        0.2057  3.4167\n","     37        0.0239       0.9696        0.1988  3.3817\n","     38        0.0190       0.9725        0.1963  4.0041\n","     39        0.0214       0.9664        0.2210  3.4156\n","     40        \u001b[36m0.0176\u001b[0m       0.9728        0.1937  3.4149\n","     41        0.0186       0.9724        0.1918  4.0397\n","     42        \u001b[36m0.0147\u001b[0m       \u001b[32m0.9741\u001b[0m        0.1970  3.5132\n","     43        \u001b[36m0.0145\u001b[0m       0.9711        0.2177  3.5155\n","     44        0.0147       0.9688        0.2285  4.1218\n","     45        0.0198       0.9741        0.1823  3.5376\n","     46        \u001b[36m0.0126\u001b[0m       \u001b[32m0.9742\u001b[0m        0.2025  3.5383\n","     47        0.0148       0.9731        0.1968  3.8984\n","     48        0.0155       0.9712        0.1950  3.7940\n","     49        0.0129       0.9709        0.2276  3.5447\n","     50        0.0149       0.9739        0.1857  3.6376\n","[CV] END lr=0.0001, max_epochs=50, module__num_layers=3, module__num_units=256; total time= 2.9min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m1.9097\u001b[0m       \u001b[32m0.8359\u001b[0m        \u001b[35m0.6265\u001b[0m  3.2502\n","      2        \u001b[36m0.7636\u001b[0m       \u001b[32m0.9086\u001b[0m        \u001b[35m0.3180\u001b[0m  3.1299\n","      3        \u001b[36m0.4941\u001b[0m       \u001b[32m0.9286\u001b[0m        \u001b[35m0.2504\u001b[0m  3.1145\n","      4        \u001b[36m0.3766\u001b[0m       \u001b[32m0.9405\u001b[0m        \u001b[35m0.2109\u001b[0m  3.7855\n","      5        \u001b[36m0.3038\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m0.1894\u001b[0m  3.1762\n","      6        \u001b[36m0.2612\u001b[0m       \u001b[32m0.9531\u001b[0m        \u001b[35m0.1685\u001b[0m  3.2375\n","      7        \u001b[36m0.2255\u001b[0m       \u001b[32m0.9584\u001b[0m        \u001b[35m0.1556\u001b[0m  3.5537\n","      8        \u001b[36m0.1963\u001b[0m       0.9584        \u001b[35m0.1516\u001b[0m  3.4831\n","      9        \u001b[36m0.1768\u001b[0m       \u001b[32m0.9609\u001b[0m        \u001b[35m0.1438\u001b[0m  3.2196\n","     10        \u001b[36m0.1520\u001b[0m       \u001b[32m0.9650\u001b[0m        \u001b[35m0.1367\u001b[0m  3.2028\n","     11        \u001b[36m0.1399\u001b[0m       \u001b[32m0.9653\u001b[0m        \u001b[35m0.1313\u001b[0m  3.8304\n","     12        \u001b[36m0.1230\u001b[0m       \u001b[32m0.9680\u001b[0m        \u001b[35m0.1282\u001b[0m  3.1998\n","     13        \u001b[36m0.1116\u001b[0m       \u001b[32m0.9706\u001b[0m        \u001b[35m0.1249\u001b[0m  3.2609\n","     14        \u001b[36m0.0945\u001b[0m       0.9700        \u001b[35m0.1241\u001b[0m  3.5893\n","     15        \u001b[36m0.0898\u001b[0m       \u001b[32m0.9708\u001b[0m        0.1244  3.4640\n","     16        \u001b[36m0.0812\u001b[0m       0.9695        0.1319  3.2271\n","     17        \u001b[36m0.0730\u001b[0m       \u001b[32m0.9715\u001b[0m        0.1288  3.2287\n","     18        \u001b[36m0.0664\u001b[0m       \u001b[32m0.9725\u001b[0m        0.1319  3.8461\n","     19        \u001b[36m0.0624\u001b[0m       0.9712        0.1318  3.2628\n","     20        \u001b[36m0.0553\u001b[0m       \u001b[32m0.9729\u001b[0m        0.1313  3.2489\n","     21        \u001b[36m0.0479\u001b[0m       \u001b[32m0.9736\u001b[0m        0.1312  3.7579\n","     22        \u001b[36m0.0434\u001b[0m       0.9736        0.1384  3.4057\n","     23        \u001b[36m0.0422\u001b[0m       \u001b[32m0.9750\u001b[0m        0.1350  3.2669\n","     24        \u001b[36m0.0421\u001b[0m       0.9724        0.1468  3.2708\n","     25        \u001b[36m0.0367\u001b[0m       0.9748        0.1377  3.8646\n","     26        \u001b[36m0.0329\u001b[0m       0.9741        0.1463  3.2768\n","     27        0.0341       0.9741        0.1449  3.2954\n","     28        \u001b[36m0.0282\u001b[0m       0.9739        0.1438  3.8963\n","     29        \u001b[36m0.0253\u001b[0m       \u001b[32m0.9754\u001b[0m        0.1472  3.3053\n","     30        \u001b[36m0.0245\u001b[0m       0.9738        0.1646  3.3312\n","     31        \u001b[36m0.0235\u001b[0m       0.9715        0.1698  3.4235\n","     32        \u001b[36m0.0210\u001b[0m       0.9748        0.1573  3.8950\n","     33        \u001b[36m0.0198\u001b[0m       0.9729        0.1793  3.3614\n","     34        \u001b[36m0.0193\u001b[0m       \u001b[32m0.9762\u001b[0m        0.1605  3.4170\n","     35        0.0221       0.9760        0.1626  4.0024\n","     36        \u001b[36m0.0187\u001b[0m       0.9742        0.1753  3.4260\n","     37        0.0249       0.9749        0.1618  3.4569\n","     38        0.0204       0.9751        0.1606  4.0637\n","     39        \u001b[36m0.0146\u001b[0m       0.9720        0.1837  3.4713\n","     40        0.0162       0.9741        0.1819  3.6399\n","     41        0.0170       0.9716        0.2030  4.9384\n","     42        \u001b[36m0.0137\u001b[0m       0.9756        0.1885  4.5450\n","     43        0.0144       0.9730        0.2129  3.5796\n","     44        0.0141       0.9750        0.1957  4.1762\n","     45        \u001b[36m0.0136\u001b[0m       0.9759        0.1875  3.7166\n","     46        \u001b[36m0.0131\u001b[0m       0.9745        0.2044  3.6265\n","     47        0.0172       0.9741        0.1818  3.9981\n","     48        0.0133       0.9760        0.1779  3.8173\n","     49        0.0131       0.9754        0.1837  3.6025\n","     50        \u001b[36m0.0099\u001b[0m       0.9740        0.2019  3.8524\n","[CV] END lr=0.0001, max_epochs=50, module__num_layers=3, module__num_units=256; total time= 3.0min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m1.9789\u001b[0m       \u001b[32m0.8134\u001b[0m        \u001b[35m0.6904\u001b[0m  3.1818\n","      2        \u001b[36m0.8146\u001b[0m       \u001b[32m0.9026\u001b[0m        \u001b[35m0.3523\u001b[0m  3.1668\n","      3        \u001b[36m0.5352\u001b[0m       \u001b[32m0.9276\u001b[0m        \u001b[35m0.2572\u001b[0m  3.1642\n","      4        \u001b[36m0.4025\u001b[0m       \u001b[32m0.9433\u001b[0m        \u001b[35m0.2120\u001b[0m  3.8404\n","      5        \u001b[36m0.3308\u001b[0m       \u001b[32m0.9461\u001b[0m        \u001b[35m0.1874\u001b[0m  3.2483\n","      6        \u001b[36m0.2822\u001b[0m       \u001b[32m0.9519\u001b[0m        \u001b[35m0.1722\u001b[0m  3.2299\n","      7        \u001b[36m0.2387\u001b[0m       \u001b[32m0.9573\u001b[0m        \u001b[35m0.1529\u001b[0m  3.9085\n","      8        \u001b[36m0.2088\u001b[0m       \u001b[32m0.9586\u001b[0m        \u001b[35m0.1474\u001b[0m  3.2632\n","      9        \u001b[36m0.1856\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1405\u001b[0m  3.3190\n","     10        \u001b[36m0.1645\u001b[0m       \u001b[32m0.9644\u001b[0m        \u001b[35m0.1341\u001b[0m  3.2827\n","     11        \u001b[36m0.1486\u001b[0m       \u001b[32m0.9657\u001b[0m        \u001b[35m0.1285\u001b[0m  3.9165\n","     12        \u001b[36m0.1352\u001b[0m       0.9653        \u001b[35m0.1263\u001b[0m  3.2867\n","     13        \u001b[36m0.1186\u001b[0m       \u001b[32m0.9684\u001b[0m        \u001b[35m0.1219\u001b[0m  3.2788\n","     14        \u001b[36m0.1052\u001b[0m       0.9674        0.1222  3.9063\n","     15        \u001b[36m0.0976\u001b[0m       \u001b[32m0.9688\u001b[0m        \u001b[35m0.1208\u001b[0m  3.2672\n","     16        \u001b[36m0.0851\u001b[0m       \u001b[32m0.9694\u001b[0m        \u001b[35m0.1188\u001b[0m  3.2904\n","     17        \u001b[36m0.0770\u001b[0m       \u001b[32m0.9698\u001b[0m        0.1207  3.5045\n","     18        \u001b[36m0.0721\u001b[0m       \u001b[32m0.9705\u001b[0m        0.1219  3.7063\n","     19        \u001b[36m0.0637\u001b[0m       0.9699        0.1214  3.2700\n","     20        \u001b[36m0.0628\u001b[0m       \u001b[32m0.9722\u001b[0m        0.1288  3.3188\n","     21        \u001b[36m0.0539\u001b[0m       0.9712        0.1309  3.9220\n","     22        0.0542       \u001b[32m0.9729\u001b[0m        0.1335  3.2657\n","     23        \u001b[36m0.0446\u001b[0m       0.9720        0.1314  3.2541\n","     24        0.0466       0.9728        0.1356  3.7170\n","     25        \u001b[36m0.0415\u001b[0m       0.9722        0.1422  3.4849\n","     26        \u001b[36m0.0401\u001b[0m       0.9716        0.1405  3.2730\n","     27        \u001b[36m0.0357\u001b[0m       0.9725        0.1409  3.2679\n","     28        \u001b[36m0.0343\u001b[0m       \u001b[32m0.9748\u001b[0m        0.1466  3.9062\n","     29        \u001b[36m0.0310\u001b[0m       \u001b[32m0.9749\u001b[0m        0.1444  3.2885\n","     30        0.0315       0.9711        0.1507  3.2892\n","     31        \u001b[36m0.0276\u001b[0m       0.9721        0.1571  4.0178\n","     32        0.0287       0.9721        0.1521  3.3951\n","     33        \u001b[36m0.0244\u001b[0m       0.9736        0.1525  3.3416\n","     34        0.0244       0.9742        0.1487  3.4358\n","     35        0.0254       0.9739        0.1592  3.8457\n","     36        0.0279       0.9730        0.1570  3.4129\n","     37        \u001b[36m0.0217\u001b[0m       0.9728        0.1603  3.4301\n","     38        \u001b[36m0.0190\u001b[0m       0.9731        0.1572  4.0292\n","     39        \u001b[36m0.0189\u001b[0m       0.9740        0.1501  3.4774\n","     40        0.0196       0.9736        0.1589  3.4638\n","     41        \u001b[36m0.0156\u001b[0m       0.9738        0.1625  4.0921\n","     42        0.0187       0.9749        0.1620  3.5294\n","     43        0.0189       0.9726        0.1722  3.5190\n","     44        \u001b[36m0.0141\u001b[0m       0.9740        0.1783  4.1217\n","     45        0.0158       \u001b[32m0.9751\u001b[0m        0.1723  3.6551\n","     46        0.0170       0.9722        0.1897  3.5710\n","     47        0.0204       0.9744        0.1631  3.8398\n","     48        0.0151       \u001b[32m0.9754\u001b[0m        0.1676  3.9061\n","     49        \u001b[36m0.0128\u001b[0m       0.9731        0.1847  3.5119\n","     50        0.0167       0.9738        0.1698  3.5562\n","[CV] END lr=0.0001, max_epochs=50, module__num_layers=3, module__num_units=256; total time= 3.0min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.3747\u001b[0m       \u001b[32m0.2697\u001b[0m        \u001b[35m2.2703\u001b[0m  2.3897\n","      2        \u001b[36m2.2150\u001b[0m       \u001b[32m0.3439\u001b[0m        \u001b[35m2.0098\u001b[0m  2.2451\n","      3        \u001b[36m1.8980\u001b[0m       \u001b[32m0.5175\u001b[0m        \u001b[35m1.3948\u001b[0m  2.1752\n","      4        \u001b[36m1.4458\u001b[0m       \u001b[32m0.5626\u001b[0m        \u001b[35m0.9968\u001b[0m  2.2276\n","      5        \u001b[36m1.1637\u001b[0m       \u001b[32m0.7444\u001b[0m        \u001b[35m0.8344\u001b[0m  2.6384\n","      6        \u001b[36m0.9972\u001b[0m       \u001b[32m0.8176\u001b[0m        \u001b[35m0.7296\u001b[0m  2.4912\n","      7        \u001b[36m0.8691\u001b[0m       \u001b[32m0.8741\u001b[0m        \u001b[35m0.6384\u001b[0m  2.3452\n","      8        \u001b[36m0.7659\u001b[0m       \u001b[32m0.8768\u001b[0m        \u001b[35m0.5466\u001b[0m  2.2702\n","      9        \u001b[36m0.6620\u001b[0m       \u001b[32m0.8924\u001b[0m        \u001b[35m0.4746\u001b[0m  2.3087\n","     10        \u001b[36m0.5843\u001b[0m       \u001b[32m0.9100\u001b[0m        \u001b[35m0.4068\u001b[0m  2.8583\n","     11        \u001b[36m0.5042\u001b[0m       \u001b[32m0.9295\u001b[0m        \u001b[35m0.3546\u001b[0m  2.3785\n","     12        \u001b[36m0.4433\u001b[0m       \u001b[32m0.9357\u001b[0m        \u001b[35m0.3047\u001b[0m  2.2941\n","     13        \u001b[36m0.3920\u001b[0m       \u001b[32m0.9413\u001b[0m        \u001b[35m0.2749\u001b[0m  2.2541\n","     14        \u001b[36m0.3622\u001b[0m       \u001b[32m0.9440\u001b[0m        \u001b[35m0.2603\u001b[0m  2.2670\n","     15        \u001b[36m0.3276\u001b[0m       \u001b[32m0.9473\u001b[0m        \u001b[35m0.2338\u001b[0m  2.8871\n","     16        \u001b[36m0.2969\u001b[0m       \u001b[32m0.9499\u001b[0m        \u001b[35m0.2216\u001b[0m  2.2850\n","     17        \u001b[36m0.2608\u001b[0m       \u001b[32m0.9526\u001b[0m        \u001b[35m0.2187\u001b[0m  2.2961\n","     18        \u001b[36m0.2507\u001b[0m       0.9507        \u001b[35m0.2185\u001b[0m  2.2940\n","     19        \u001b[36m0.2296\u001b[0m       \u001b[32m0.9556\u001b[0m        \u001b[35m0.2072\u001b[0m  2.2837\n","     20        \u001b[36m0.2191\u001b[0m       0.9531        0.2133  2.9229\n","     21        \u001b[36m0.2009\u001b[0m       \u001b[32m0.9563\u001b[0m        0.2106  2.3287\n","     22        \u001b[36m0.1922\u001b[0m       \u001b[32m0.9600\u001b[0m        \u001b[35m0.1955\u001b[0m  2.3082\n","     23        \u001b[36m0.1766\u001b[0m       0.9585        0.2030  2.3124\n","     24        \u001b[36m0.1692\u001b[0m       0.9586        0.2071  2.2953\n","     25        \u001b[36m0.1623\u001b[0m       \u001b[32m0.9621\u001b[0m        0.2049  2.9298\n","     26        \u001b[36m0.1544\u001b[0m       0.9593        0.2078  2.3136\n","     27        \u001b[36m0.1481\u001b[0m       0.9600        0.2046  2.3182\n","     28        \u001b[36m0.1367\u001b[0m       0.9604        0.2094  2.4233\n","     29        \u001b[36m0.1289\u001b[0m       0.9614        0.2076  2.3401\n","     30        0.1319       0.9617        0.2096  2.9401\n","     31        \u001b[36m0.1202\u001b[0m       0.9613        0.2058  2.3725\n","     32        0.1216       \u001b[32m0.9625\u001b[0m        0.2039  2.3671\n","     33        \u001b[36m0.1092\u001b[0m       0.9609        0.2106  2.3676\n","     34        \u001b[36m0.1057\u001b[0m       \u001b[32m0.9627\u001b[0m        0.2088  2.7037\n","     35        0.1072       \u001b[32m0.9650\u001b[0m        0.2006  2.6480\n","     36        \u001b[36m0.0975\u001b[0m       0.9621        0.2185  2.3715\n","     37        0.1022       0.9617        0.2151  2.4008\n","     38        0.0987       0.9626        0.2148  2.3816\n","     39        0.1008       0.9621        0.2177  2.9857\n","     40        \u001b[36m0.0813\u001b[0m       \u001b[32m0.9654\u001b[0m        0.2278  2.3759\n","     41        0.0873       0.9651        0.2293  2.4097\n","     42        0.0863       0.9643        0.2375  2.3994\n","     43        0.0859       0.9641        0.2385  2.3913\n","     44        0.0855       \u001b[32m0.9657\u001b[0m        0.2244  3.0081\n","     45        0.0817       0.9650        0.2444  2.4039\n","     46        \u001b[36m0.0742\u001b[0m       0.9651        0.2226  2.4592\n","     47        \u001b[36m0.0727\u001b[0m       0.9656        0.2302  2.4220\n","     48        0.0739       0.9654        0.2264  2.7489\n","     49        \u001b[36m0.0687\u001b[0m       0.9653        0.2419  2.7687\n","     50        \u001b[36m0.0649\u001b[0m       \u001b[32m0.9660\u001b[0m        0.2315  2.4321\n","[CV] END lr=0.0001, max_epochs=50, module__num_layers=5, module__num_units=128; total time= 2.1min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.3376\u001b[0m       \u001b[32m0.2381\u001b[0m        \u001b[35m2.2257\u001b[0m  2.2016\n","      2        \u001b[36m2.1004\u001b[0m       \u001b[32m0.4451\u001b[0m        \u001b[35m1.7756\u001b[0m  2.2125\n","      3        \u001b[36m1.6748\u001b[0m       \u001b[32m0.5098\u001b[0m        \u001b[35m1.3594\u001b[0m  2.8519\n","      4        \u001b[36m1.4378\u001b[0m       \u001b[32m0.5775\u001b[0m        \u001b[35m1.2277\u001b[0m  2.2575\n","      5        \u001b[36m1.2970\u001b[0m       \u001b[32m0.6534\u001b[0m        \u001b[35m1.0666\u001b[0m  2.2640\n","      6        \u001b[36m1.1485\u001b[0m       \u001b[32m0.7344\u001b[0m        \u001b[35m0.8895\u001b[0m  2.2846\n","      7        \u001b[36m0.9975\u001b[0m       \u001b[32m0.8189\u001b[0m        \u001b[35m0.7656\u001b[0m  2.2766\n","      8        \u001b[36m0.8703\u001b[0m       \u001b[32m0.8365\u001b[0m        \u001b[35m0.6130\u001b[0m  2.9231\n","      9        \u001b[36m0.7484\u001b[0m       \u001b[32m0.8504\u001b[0m        \u001b[35m0.5355\u001b[0m  2.2996\n","     10        \u001b[36m0.6516\u001b[0m       \u001b[32m0.8570\u001b[0m        \u001b[35m0.4577\u001b[0m  2.3027\n","     11        \u001b[36m0.5774\u001b[0m       \u001b[32m0.8596\u001b[0m        \u001b[35m0.4156\u001b[0m  2.2956\n","     12        \u001b[36m0.5237\u001b[0m       \u001b[32m0.8615\u001b[0m        \u001b[35m0.3846\u001b[0m  2.3342\n","     13        \u001b[36m0.4758\u001b[0m       \u001b[32m0.8656\u001b[0m        \u001b[35m0.3704\u001b[0m  2.9499\n","     14        \u001b[36m0.4460\u001b[0m       \u001b[32m0.8675\u001b[0m        \u001b[35m0.3513\u001b[0m  2.3473\n","     15        \u001b[36m0.4131\u001b[0m       \u001b[32m0.8692\u001b[0m        0.3522  2.3236\n","     16        \u001b[36m0.3913\u001b[0m       \u001b[32m0.8694\u001b[0m        \u001b[35m0.3450\u001b[0m  2.3634\n","     17        \u001b[36m0.3772\u001b[0m       \u001b[32m0.8734\u001b[0m        \u001b[35m0.3346\u001b[0m  2.4988\n","     18        \u001b[36m0.3528\u001b[0m       0.8729        \u001b[35m0.3227\u001b[0m  2.8562\n","     19        \u001b[36m0.3426\u001b[0m       \u001b[32m0.8748\u001b[0m        \u001b[35m0.3217\u001b[0m  2.3726\n","     20        \u001b[36m0.3297\u001b[0m       \u001b[32m0.8769\u001b[0m        0.3245  2.3826\n","     21        \u001b[36m0.3240\u001b[0m       0.8741        0.3229  2.3643\n","     22        \u001b[36m0.3082\u001b[0m       0.8768        0.3330  2.7942\n","     23        \u001b[36m0.2972\u001b[0m       \u001b[32m0.8774\u001b[0m        0.3254  2.5640\n","     24        \u001b[36m0.2905\u001b[0m       \u001b[32m0.8776\u001b[0m        0.3302  2.3576\n","     25        \u001b[36m0.2851\u001b[0m       0.8771        \u001b[35m0.3172\u001b[0m  2.3874\n","     26        \u001b[36m0.2741\u001b[0m       \u001b[32m0.8790\u001b[0m        0.3192  2.4518\n","     27        \u001b[36m0.2672\u001b[0m       \u001b[32m0.8792\u001b[0m        0.3319  3.0139\n","     28        0.2677       \u001b[32m0.8808\u001b[0m        \u001b[35m0.3045\u001b[0m  2.4016\n","     29        \u001b[36m0.2576\u001b[0m       \u001b[32m0.8816\u001b[0m        0.3205  2.4193\n","     30        0.2577       0.8809        0.3067  2.3920\n","     31        \u001b[36m0.2467\u001b[0m       0.8811        0.3315  2.4319\n","     32        0.2470       \u001b[32m0.8824\u001b[0m        0.3233  2.9849\n","     33        \u001b[36m0.2420\u001b[0m       \u001b[32m0.8826\u001b[0m        0.3211  2.4509\n","     34        \u001b[36m0.2411\u001b[0m       \u001b[32m0.8829\u001b[0m        0.3201  2.4166\n","     35        \u001b[36m0.2301\u001b[0m       0.8828        0.3255  2.4227\n","     36        0.2355       0.8819        0.3314  2.9114\n","     37        \u001b[36m0.2292\u001b[0m       0.8821        0.3410  2.5814\n","     38        \u001b[36m0.2227\u001b[0m       \u001b[32m0.8832\u001b[0m        0.3297  2.5067\n","     39        \u001b[36m0.2220\u001b[0m       \u001b[32m0.8834\u001b[0m        0.3366  2.4925\n","     40        \u001b[36m0.2181\u001b[0m       \u001b[32m0.8840\u001b[0m        0.3304  2.4960\n","     41        0.2191       0.8834        0.3410  3.0831\n","     42        \u001b[36m0.2161\u001b[0m       0.8814        0.3447  2.4849\n","     43        0.2234       0.8826        0.3289  2.5008\n","     44        0.2165       0.8810        0.3475  2.5409\n","     45        \u001b[36m0.2111\u001b[0m       \u001b[32m0.8849\u001b[0m        0.3274  3.0409\n","     46        \u001b[36m0.2060\u001b[0m       \u001b[32m0.8860\u001b[0m        0.3101  2.6763\n","     47        0.2070       0.8854        0.3287  2.5221\n","     48        \u001b[36m0.2024\u001b[0m       0.8846        0.3338  2.5377\n","     49        \u001b[36m0.1992\u001b[0m       0.8854        0.3326  2.5306\n","     50        \u001b[36m0.1948\u001b[0m       0.8845        0.3514  3.1122\n","[CV] END lr=0.0001, max_epochs=50, module__num_layers=5, module__num_units=128; total time= 2.1min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.3438\u001b[0m       \u001b[32m0.2815\u001b[0m        \u001b[35m2.2606\u001b[0m  2.2116\n","      2        \u001b[36m2.1768\u001b[0m       \u001b[32m0.3937\u001b[0m        \u001b[35m2.0188\u001b[0m  2.2037\n","      3        \u001b[36m1.8762\u001b[0m       \u001b[32m0.5524\u001b[0m        \u001b[35m1.3191\u001b[0m  2.2162\n","      4        \u001b[36m1.3893\u001b[0m       \u001b[32m0.6236\u001b[0m        \u001b[35m0.9450\u001b[0m  2.6348\n","      5        \u001b[36m1.1101\u001b[0m       \u001b[32m0.7220\u001b[0m        \u001b[35m0.7847\u001b[0m  2.5276\n","      6        \u001b[36m0.9515\u001b[0m       \u001b[32m0.7986\u001b[0m        \u001b[35m0.6572\u001b[0m  2.2824\n","      7        \u001b[36m0.8265\u001b[0m       \u001b[32m0.8576\u001b[0m        \u001b[35m0.5356\u001b[0m  2.3252\n","      8        \u001b[36m0.7109\u001b[0m       \u001b[32m0.8725\u001b[0m        \u001b[35m0.4482\u001b[0m  2.2907\n","      9        \u001b[36m0.6140\u001b[0m       \u001b[32m0.9091\u001b[0m        \u001b[35m0.4139\u001b[0m  2.8077\n","     10        \u001b[36m0.5531\u001b[0m       \u001b[32m0.9247\u001b[0m        \u001b[35m0.3640\u001b[0m  2.4341\n","     11        \u001b[36m0.4913\u001b[0m       \u001b[32m0.9319\u001b[0m        \u001b[35m0.3284\u001b[0m  2.3013\n","     12        \u001b[36m0.4413\u001b[0m       \u001b[32m0.9375\u001b[0m        \u001b[35m0.2822\u001b[0m  2.2787\n","     13        \u001b[36m0.3944\u001b[0m       \u001b[32m0.9447\u001b[0m        \u001b[35m0.2415\u001b[0m  2.3249\n","     14        \u001b[36m0.3563\u001b[0m       \u001b[32m0.9477\u001b[0m        \u001b[35m0.2236\u001b[0m  2.9712\n","     15        \u001b[36m0.3137\u001b[0m       \u001b[32m0.9524\u001b[0m        \u001b[35m0.2112\u001b[0m  2.3415\n","     16        \u001b[36m0.2812\u001b[0m       \u001b[32m0.9539\u001b[0m        \u001b[35m0.1973\u001b[0m  2.3405\n","     17        \u001b[36m0.2669\u001b[0m       \u001b[32m0.9543\u001b[0m        0.2004  2.3333\n","     18        \u001b[36m0.2431\u001b[0m       \u001b[32m0.9580\u001b[0m        \u001b[35m0.1896\u001b[0m  2.3464\n","     19        \u001b[36m0.2148\u001b[0m       \u001b[32m0.9596\u001b[0m        0.1934  3.0187\n","     20        \u001b[36m0.2073\u001b[0m       \u001b[32m0.9623\u001b[0m        \u001b[35m0.1805\u001b[0m  2.3328\n","     21        \u001b[36m0.1913\u001b[0m       0.9623        0.1838  2.3337\n","     22        \u001b[36m0.1851\u001b[0m       0.9595        0.1915  2.6395\n","     23        \u001b[36m0.1680\u001b[0m       0.9609        0.1902  2.5086\n","     24        \u001b[36m0.1518\u001b[0m       \u001b[32m0.9634\u001b[0m        0.1907  2.8387\n","     25        \u001b[36m0.1394\u001b[0m       0.9613        0.1912  2.3668\n","     26        0.1439       0.9613        0.1939  2.3493\n","     27        \u001b[36m0.1392\u001b[0m       0.9624        0.1893  2.3576\n","     28        \u001b[36m0.1281\u001b[0m       0.9624        0.1976  2.7694\n","     29        \u001b[36m0.1185\u001b[0m       \u001b[32m0.9665\u001b[0m        0.1849  2.6350\n","     30        \u001b[36m0.1149\u001b[0m       0.9643        0.1929  2.3845\n","     31        \u001b[36m0.1130\u001b[0m       \u001b[32m0.9669\u001b[0m        0.1853  2.3846\n","     32        \u001b[36m0.1088\u001b[0m       0.9669        0.1894  2.3744\n","     33        \u001b[36m0.0986\u001b[0m       0.9669        0.1963  3.0092\n","     34        \u001b[36m0.0936\u001b[0m       0.9653        0.2126  2.4234\n","     35        0.0962       \u001b[32m0.9684\u001b[0m        0.1889  2.4194\n","     36        \u001b[36m0.0901\u001b[0m       0.9665        0.1946  2.4046\n","     37        \u001b[36m0.0836\u001b[0m       0.9667        0.2042  2.4556\n","     38        0.0909       \u001b[32m0.9690\u001b[0m        0.1900  3.0312\n","     39        \u001b[36m0.0796\u001b[0m       0.9685        0.1930  2.4614\n","     40        \u001b[36m0.0784\u001b[0m       0.9661        0.2028  2.4267\n","     41        \u001b[36m0.0770\u001b[0m       0.9686        0.2041  2.4705\n","     42        \u001b[36m0.0725\u001b[0m       0.9689        0.2031  3.0028\n","     43        \u001b[36m0.0699\u001b[0m       0.9674        0.2019  2.5358\n","     44        \u001b[36m0.0699\u001b[0m       \u001b[32m0.9691\u001b[0m        0.2068  2.4564\n","     45        \u001b[36m0.0685\u001b[0m       0.9688        0.2066  2.4996\n","     46        \u001b[36m0.0654\u001b[0m       0.9675        0.2138  2.4697\n","     47        \u001b[36m0.0596\u001b[0m       0.9690        0.2259  3.1329\n","     48        0.0646       0.9680        0.2235  2.5407\n","     49        0.0648       \u001b[32m0.9696\u001b[0m        0.2113  2.5155\n","     50        \u001b[36m0.0574\u001b[0m       0.9695        0.2098  2.5266\n","[CV] END lr=0.0001, max_epochs=50, module__num_layers=5, module__num_units=128; total time= 2.1min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.2964\u001b[0m       \u001b[32m0.4751\u001b[0m        \u001b[35m1.9349\u001b[0m  4.7212\n","      2        \u001b[36m1.4486\u001b[0m       \u001b[32m0.7013\u001b[0m        \u001b[35m0.7630\u001b[0m  4.0585\n","      3        \u001b[36m0.8329\u001b[0m       \u001b[32m0.8920\u001b[0m        \u001b[35m0.4221\u001b[0m  4.1873\n","      4        \u001b[36m0.5565\u001b[0m       \u001b[32m0.9239\u001b[0m        \u001b[35m0.2895\u001b[0m  4.6005\n","      5        \u001b[36m0.4002\u001b[0m       \u001b[32m0.9354\u001b[0m        \u001b[35m0.2517\u001b[0m  4.1325\n","      6        \u001b[36m0.3195\u001b[0m       \u001b[32m0.9455\u001b[0m        \u001b[35m0.2200\u001b[0m  4.8178\n","      7        \u001b[36m0.2644\u001b[0m       \u001b[32m0.9513\u001b[0m        \u001b[35m0.2098\u001b[0m  4.1859\n","      8        \u001b[36m0.2262\u001b[0m       \u001b[32m0.9541\u001b[0m        \u001b[35m0.2008\u001b[0m  4.1438\n","      9        \u001b[36m0.1953\u001b[0m       \u001b[32m0.9565\u001b[0m        \u001b[35m0.1904\u001b[0m  4.7644\n","     10        \u001b[36m0.1772\u001b[0m       \u001b[32m0.9597\u001b[0m        \u001b[35m0.1848\u001b[0m  4.2228\n","     11        \u001b[36m0.1533\u001b[0m       0.9585        0.1914  4.2319\n","     12        \u001b[36m0.1425\u001b[0m       \u001b[32m0.9634\u001b[0m        \u001b[35m0.1788\u001b[0m  4.8949\n","     13        \u001b[36m0.1232\u001b[0m       \u001b[32m0.9660\u001b[0m        \u001b[35m0.1649\u001b[0m  4.2345\n","     14        \u001b[36m0.1101\u001b[0m       0.9649        0.1809  4.8654\n","     15        \u001b[36m0.1001\u001b[0m       \u001b[32m0.9664\u001b[0m        0.1759  4.2025\n","     16        \u001b[36m0.0930\u001b[0m       0.9659        0.1803  4.2748\n","     17        \u001b[36m0.0823\u001b[0m       \u001b[32m0.9679\u001b[0m        0.1756  4.8477\n","     18        \u001b[36m0.0791\u001b[0m       0.9655        0.1813  4.3010\n","     19        \u001b[36m0.0688\u001b[0m       0.9666        0.1901  4.3323\n","     20        \u001b[36m0.0639\u001b[0m       0.9674        0.1965  4.8451\n","     21        \u001b[36m0.0599\u001b[0m       0.9673        0.1931  4.2812\n","     22        \u001b[36m0.0593\u001b[0m       0.9673        0.2104  4.9566\n","     23        \u001b[36m0.0499\u001b[0m       \u001b[32m0.9701\u001b[0m        0.2034  4.3234\n","     24        0.0503       0.9688        0.2027  4.3681\n","     25        \u001b[36m0.0438\u001b[0m       0.9679        0.2211  5.0326\n","     26        0.0466       0.9667        0.2149  4.4299\n","     27        \u001b[36m0.0367\u001b[0m       0.9699        0.2245  4.9827\n","     28        0.0384       0.9700        0.2117  4.4940\n","     29        0.0379       0.9680        0.2308  4.4017\n","     30        \u001b[36m0.0353\u001b[0m       \u001b[32m0.9721\u001b[0m        0.2100  5.0453\n","     31        0.0359       0.9688        0.2266  4.4359\n","     32        \u001b[36m0.0304\u001b[0m       0.9708        0.2165  4.8422\n","     33        \u001b[36m0.0267\u001b[0m       0.9710        0.2272  4.7914\n","     34        0.0284       0.9716        0.2268  4.5274\n","     35        0.0313       0.9680        0.2439  5.1286\n","     36        0.0281       0.9694        0.2330  4.4469\n","     37        0.0336       0.9710        0.2258  4.7580\n","     38        \u001b[36m0.0242\u001b[0m       0.9709        0.2469  4.8926\n","     39        \u001b[36m0.0221\u001b[0m       0.9721        0.2459  4.5954\n","     40        0.0245       0.9699        0.2417  5.2031\n","     41        0.0281       \u001b[32m0.9725\u001b[0m        0.2348  4.5943\n","     42        0.0226       \u001b[32m0.9726\u001b[0m        0.2392  5.1442\n","     43        0.0271       0.9714        0.2221  4.6881\n","     44        \u001b[36m0.0166\u001b[0m       0.9696        0.2688  4.6643\n","     45        0.0175       0.9699        0.2599  5.3677\n","     46        0.0217       0.9712        0.2569  4.8064\n","     47        0.0177       0.9716        0.2380  5.2764\n","     48        0.0198       0.9685        0.2608  4.7637\n","     49        \u001b[36m0.0157\u001b[0m       0.9716        0.2659  5.1245\n","     50        0.0162       0.9725        0.2784  5.2121\n","[CV] END lr=0.0001, max_epochs=50, module__num_layers=5, module__num_units=256; total time= 3.9min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.2872\u001b[0m       \u001b[32m0.3591\u001b[0m        \u001b[35m2.0425\u001b[0m  4.0307\n","      2        \u001b[36m1.6188\u001b[0m       \u001b[32m0.7179\u001b[0m        \u001b[35m0.7644\u001b[0m  4.6386\n","      3        \u001b[36m0.8311\u001b[0m       \u001b[32m0.8755\u001b[0m        \u001b[35m0.3955\u001b[0m  4.0156\n","      4        \u001b[36m0.5274\u001b[0m       \u001b[32m0.9316\u001b[0m        \u001b[35m0.2689\u001b[0m  4.1042\n","      5        \u001b[36m0.3928\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m0.2171\u001b[0m  4.7101\n","      6        \u001b[36m0.3099\u001b[0m       \u001b[32m0.9487\u001b[0m        \u001b[35m0.1924\u001b[0m  4.0934\n","      7        \u001b[36m0.2642\u001b[0m       \u001b[32m0.9555\u001b[0m        \u001b[35m0.1759\u001b[0m  4.7472\n","      8        \u001b[36m0.2294\u001b[0m       \u001b[32m0.9587\u001b[0m        \u001b[35m0.1641\u001b[0m  4.2021\n","      9        \u001b[36m0.1955\u001b[0m       \u001b[32m0.9601\u001b[0m        \u001b[35m0.1575\u001b[0m  4.1250\n","     10        \u001b[36m0.1808\u001b[0m       \u001b[32m0.9637\u001b[0m        \u001b[35m0.1550\u001b[0m  5.0288\n","     11        \u001b[36m0.1581\u001b[0m       \u001b[32m0.9639\u001b[0m        \u001b[35m0.1519\u001b[0m  4.1563\n","     12        \u001b[36m0.1431\u001b[0m       \u001b[32m0.9645\u001b[0m        0.1597  4.1644\n","     13        \u001b[36m0.1304\u001b[0m       \u001b[32m0.9677\u001b[0m        \u001b[35m0.1449\u001b[0m  4.8360\n","     14        \u001b[36m0.1163\u001b[0m       \u001b[32m0.9686\u001b[0m        0.1462  4.2055\n","     15        \u001b[36m0.1094\u001b[0m       0.9666        0.1480  4.7099\n","     16        \u001b[36m0.0979\u001b[0m       \u001b[32m0.9702\u001b[0m        \u001b[35m0.1413\u001b[0m  4.3761\n","     17        \u001b[36m0.0891\u001b[0m       \u001b[32m0.9714\u001b[0m        \u001b[35m0.1355\u001b[0m  4.1997\n","     18        \u001b[36m0.0827\u001b[0m       0.9698        0.1425  4.8795\n","     19        \u001b[36m0.0736\u001b[0m       0.9702        0.1486  4.2117\n","     20        \u001b[36m0.0715\u001b[0m       0.9711        0.1434  4.2226\n","     21        \u001b[36m0.0653\u001b[0m       \u001b[32m0.9732\u001b[0m        0.1421  4.8935\n","     22        \u001b[36m0.0608\u001b[0m       0.9726        0.1426  4.2611\n","     23        \u001b[36m0.0578\u001b[0m       0.9725        0.1446  4.7810\n","     24        \u001b[36m0.0541\u001b[0m       0.9710        0.1493  4.4250\n","     25        \u001b[36m0.0473\u001b[0m       0.9731        0.1497  4.3399\n","     26        \u001b[36m0.0451\u001b[0m       \u001b[32m0.9735\u001b[0m        0.1465  4.9743\n","     27        \u001b[36m0.0421\u001b[0m       \u001b[32m0.9756\u001b[0m        0.1374  4.3636\n","     28        0.0442       0.9745        0.1432  4.5137\n","     29        \u001b[36m0.0396\u001b[0m       0.9715        0.1752  4.8279\n","     30        \u001b[36m0.0365\u001b[0m       0.9729        0.1704  4.3691\n","     31        \u001b[36m0.0331\u001b[0m       0.9749        0.1767  4.9865\n","     32        0.0336       0.9750        0.1646  4.4240\n","     33        \u001b[36m0.0301\u001b[0m       0.9741        0.1682  4.4760\n","     34        \u001b[36m0.0299\u001b[0m       0.9728        0.1835  5.0346\n","     35        0.0315       0.9731        0.1688  4.5071\n","     36        \u001b[36m0.0276\u001b[0m       0.9749        0.1798  5.1264\n","     37        \u001b[36m0.0261\u001b[0m       0.9742        0.1801  4.6272\n","     38        0.0291       \u001b[32m0.9760\u001b[0m        0.1738  4.5897\n","     39        0.0287       0.9745        0.1796  5.1698\n","     40        \u001b[36m0.0243\u001b[0m       \u001b[32m0.9770\u001b[0m        0.1648  4.5455\n","     41        0.0259       0.9758        0.1579  5.2243\n","     42        \u001b[36m0.0230\u001b[0m       0.9752        0.1676  4.6513\n","     43        0.0232       0.9758        0.1705  4.9021\n","     44        \u001b[36m0.0225\u001b[0m       0.9738        0.1943  5.0805\n","     45        0.0228       0.9756        0.1897  4.7337\n","     46        \u001b[36m0.0205\u001b[0m       0.9759        0.1981  5.3685\n","     47        \u001b[36m0.0152\u001b[0m       0.9749        0.2081  4.9272\n","     48        0.0229       0.9761        0.1830  5.5141\n","     49        0.0193       \u001b[32m0.9771\u001b[0m        0.1836  4.7963\n","     50        0.0163       0.9754        0.1899  5.1083\n","[CV] END lr=0.0001, max_epochs=50, module__num_layers=5, module__num_units=256; total time= 3.9min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.2672\u001b[0m       \u001b[32m0.3339\u001b[0m        \u001b[35m1.8305\u001b[0m  4.0791\n","      2        \u001b[36m1.5371\u001b[0m       \u001b[32m0.7670\u001b[0m        \u001b[35m0.7256\u001b[0m  4.0598\n","      3        \u001b[36m0.8452\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.4332\u001b[0m  4.6983\n","      4        \u001b[36m0.5725\u001b[0m       \u001b[32m0.9323\u001b[0m        \u001b[35m0.2698\u001b[0m  4.0965\n","      5        \u001b[36m0.4174\u001b[0m       \u001b[32m0.9446\u001b[0m        \u001b[35m0.2160\u001b[0m  4.0959\n","      6        \u001b[36m0.3282\u001b[0m       \u001b[32m0.9500\u001b[0m        \u001b[35m0.1918\u001b[0m  4.7185\n","      7        \u001b[36m0.2776\u001b[0m       \u001b[32m0.9561\u001b[0m        \u001b[35m0.1721\u001b[0m  4.1613\n","      8        \u001b[36m0.2327\u001b[0m       \u001b[32m0.9601\u001b[0m        \u001b[35m0.1625\u001b[0m  4.3971\n","      9        \u001b[36m0.2060\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1543\u001b[0m  4.5581\n","     10        \u001b[36m0.1773\u001b[0m       \u001b[32m0.9630\u001b[0m        \u001b[35m0.1498\u001b[0m  4.1324\n","     11        \u001b[36m0.1619\u001b[0m       \u001b[32m0.9665\u001b[0m        \u001b[35m0.1382\u001b[0m  4.8149\n","     12        \u001b[36m0.1390\u001b[0m       \u001b[32m0.9676\u001b[0m        \u001b[35m0.1369\u001b[0m  4.1508\n","     13        \u001b[36m0.1307\u001b[0m       0.9655        0.1426  4.1633\n","     14        \u001b[36m0.1198\u001b[0m       \u001b[32m0.9685\u001b[0m        \u001b[35m0.1340\u001b[0m  4.8242\n","     15        \u001b[36m0.1058\u001b[0m       \u001b[32m0.9701\u001b[0m        \u001b[35m0.1338\u001b[0m  4.2089\n","     16        \u001b[36m0.0975\u001b[0m       \u001b[32m0.9716\u001b[0m        \u001b[35m0.1309\u001b[0m  4.2516\n","     17        \u001b[36m0.0891\u001b[0m       \u001b[32m0.9718\u001b[0m        0.1313  4.8539\n","     18        \u001b[36m0.0822\u001b[0m       0.9700        0.1428  4.2264\n","     19        \u001b[36m0.0761\u001b[0m       0.9711        0.1362  4.8509\n","     20        \u001b[36m0.0671\u001b[0m       \u001b[32m0.9730\u001b[0m        0.1367  4.2443\n","     21        \u001b[36m0.0629\u001b[0m       0.9729        0.1358  4.2391\n","     22        0.0655       0.9696        0.1468  4.9034\n","     23        \u001b[36m0.0585\u001b[0m       0.9729        0.1485  4.2427\n","     24        \u001b[36m0.0516\u001b[0m       0.9718        0.1469  4.2911\n","     25        0.0518       \u001b[32m0.9746\u001b[0m        0.1488  4.8635\n","     26        \u001b[36m0.0472\u001b[0m       \u001b[32m0.9748\u001b[0m        0.1394  4.2986\n","     27        \u001b[36m0.0427\u001b[0m       0.9745        0.1388  4.9161\n","     28        \u001b[36m0.0404\u001b[0m       \u001b[32m0.9750\u001b[0m        0.1480  4.3153\n","     29        \u001b[36m0.0378\u001b[0m       0.9732        0.1542  4.3584\n","     30        \u001b[36m0.0372\u001b[0m       0.9721        0.1562  4.9789\n","     31        \u001b[36m0.0366\u001b[0m       \u001b[32m0.9760\u001b[0m        0.1528  4.3476\n","     32        \u001b[36m0.0337\u001b[0m       0.9758        0.1520  4.8798\n","     33        \u001b[36m0.0301\u001b[0m       0.9745        0.1624  4.5690\n","     34        0.0352       0.9735        0.1536  4.4304\n","     35        \u001b[36m0.0277\u001b[0m       0.9730        0.1798  5.0595\n","     36        0.0346       0.9732        0.1745  4.4254\n","     37        \u001b[36m0.0276\u001b[0m       0.9730        0.1727  4.8480\n","     38        0.0292       0.9749        0.1621  4.7673\n","     39        \u001b[36m0.0261\u001b[0m       0.9732        0.1732  4.4589\n","     40        0.0271       \u001b[32m0.9766\u001b[0m        0.1630  5.1120\n","     41        \u001b[36m0.0258\u001b[0m       0.9742        0.1745  4.5487\n","     42        \u001b[36m0.0244\u001b[0m       0.9765        0.1679  5.0248\n","     43        \u001b[36m0.0205\u001b[0m       0.9759        0.1686  4.8165\n","     44        0.0220       0.9729        0.1751  4.6109\n","     45        \u001b[36m0.0198\u001b[0m       0.9762        0.1838  5.2046\n","     46        \u001b[36m0.0181\u001b[0m       0.9761        0.1846  4.6509\n","     47        0.0185       0.9741        0.1980  5.3235\n","     48        0.0241       0.9759        0.1816  4.5661\n","     49        0.0220       \u001b[32m0.9769\u001b[0m        0.1778  4.5503\n","     50        \u001b[36m0.0167\u001b[0m       \u001b[32m0.9771\u001b[0m        0.1788  5.2816\n","[CV] END lr=0.0001, max_epochs=50, module__num_layers=5, module__num_units=256; total time= 3.8min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m1.2096\u001b[0m       \u001b[32m0.9056\u001b[0m        \u001b[35m0.3616\u001b[0m  1.8469\n","      2        \u001b[36m0.4621\u001b[0m       \u001b[32m0.9291\u001b[0m        \u001b[35m0.2936\u001b[0m  1.8593\n","      3        \u001b[36m0.3378\u001b[0m       \u001b[32m0.9386\u001b[0m        \u001b[35m0.2527\u001b[0m  1.9063\n","      4        \u001b[36m0.2713\u001b[0m       \u001b[32m0.9404\u001b[0m        0.2626  2.7504\n","      5        \u001b[36m0.2346\u001b[0m       \u001b[32m0.9516\u001b[0m        \u001b[35m0.2261\u001b[0m  2.1208\n","      6        \u001b[36m0.1934\u001b[0m       \u001b[32m0.9526\u001b[0m        \u001b[35m0.2220\u001b[0m  2.1283\n","      7        \u001b[36m0.1907\u001b[0m       0.9511        \u001b[35m0.2012\u001b[0m  2.1524\n","      8        \u001b[36m0.1721\u001b[0m       \u001b[32m0.9527\u001b[0m        0.2206  2.1205\n","      9        \u001b[36m0.1555\u001b[0m       \u001b[32m0.9541\u001b[0m        0.2199  2.5352\n","     10        \u001b[36m0.1516\u001b[0m       \u001b[32m0.9577\u001b[0m        0.2133  2.3703\n","     11        \u001b[36m0.1395\u001b[0m       0.9566        0.2148  2.1648\n","     12        \u001b[36m0.1256\u001b[0m       0.9529        0.2365  2.1724\n","     13        0.1303       0.9574        0.2094  2.1716\n","     14        \u001b[36m0.1165\u001b[0m       \u001b[32m0.9606\u001b[0m        \u001b[35m0.1928\u001b[0m  2.4164\n","     15        \u001b[36m0.1067\u001b[0m       \u001b[32m0.9619\u001b[0m        0.2033  2.5691\n","     16        0.1098       0.9579        0.2326  2.2036\n","     17        0.1106       \u001b[32m0.9627\u001b[0m        0.2038  2.2338\n","     18        \u001b[36m0.0991\u001b[0m       0.9627        0.2211  2.2266\n","     19        0.0991       0.9534        0.2842  2.3962\n","     20        \u001b[36m0.0901\u001b[0m       0.9615        0.2625  2.6478\n","     21        0.1004       0.9574        0.2458  2.2403\n","     22        0.0939       \u001b[32m0.9636\u001b[0m        0.2266  2.2411\n","     23        \u001b[36m0.0856\u001b[0m       0.9617        0.2667  2.2692\n","     24        \u001b[36m0.0802\u001b[0m       \u001b[32m0.9641\u001b[0m        0.2201  2.5144\n","     25        \u001b[36m0.0774\u001b[0m       0.9619        0.2579  2.7075\n","     26        0.0856       \u001b[32m0.9659\u001b[0m        0.2703  2.3155\n","     27        0.0817       0.9615        0.2879  2.3022\n","     28        0.0836       0.9624        0.2359  2.3185\n","     29        \u001b[36m0.0723\u001b[0m       0.9645        0.2567  2.6879\n","     30        0.0776       0.9637        0.2704  2.5685\n","     31        \u001b[36m0.0657\u001b[0m       0.9645        0.2955  2.3936\n","     32        0.0810       0.9637        0.2606  2.3881\n","     33        0.0832       0.9629        0.2770  2.3550\n","     34        \u001b[36m0.0642\u001b[0m       0.9649        0.2519  2.9317\n","     35        0.0725       \u001b[32m0.9663\u001b[0m        0.2328  2.4074\n","     36        \u001b[36m0.0607\u001b[0m       0.9630        0.2864  2.4055\n","     37        0.0653       0.9651        0.3299  2.4041\n","     38        0.0699       0.9654        0.2681  2.4039\n","     39        0.0624       0.9614        0.3146  2.9688\n","     40        0.0620       0.9656        0.2851  2.4183\n","     41        0.0655       \u001b[32m0.9667\u001b[0m        0.3042  2.4233\n","     42        \u001b[36m0.0595\u001b[0m       0.9629        0.3168  2.4151\n","     43        0.0678       0.9630        0.3085  2.7639\n","     44        \u001b[36m0.0504\u001b[0m       0.9656        0.3714  2.6897\n","     45        0.0709       0.9627        0.3396  2.4479\n","     46        0.0532       0.9621        0.3826  2.4562\n","     47        0.0574       0.9657        0.2679  2.4632\n","     48        0.0589       0.9627        0.3781  3.0451\n","     49        0.0638       0.9649        0.3092  2.4798\n","     50        0.0583       0.9626        0.3389  2.4970\n","[CV] END lr=0.001, max_epochs=50, module__num_layers=3, module__num_units=128; total time= 2.0min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m1.1259\u001b[0m       \u001b[32m0.9051\u001b[0m        \u001b[35m0.3515\u001b[0m  1.8573\n","      2        \u001b[36m0.4700\u001b[0m       \u001b[32m0.9133\u001b[0m        \u001b[35m0.3403\u001b[0m  1.8777\n","      3        \u001b[36m0.3423\u001b[0m       \u001b[32m0.9397\u001b[0m        \u001b[35m0.2339\u001b[0m  2.5310\n","      4        \u001b[36m0.2710\u001b[0m       \u001b[32m0.9525\u001b[0m        \u001b[35m0.1837\u001b[0m  2.1949\n","      5        \u001b[36m0.2350\u001b[0m       \u001b[32m0.9555\u001b[0m        \u001b[35m0.1811\u001b[0m  2.1551\n","      6        \u001b[36m0.2059\u001b[0m       \u001b[32m0.9574\u001b[0m        \u001b[35m0.1795\u001b[0m  2.1560\n","      7        \u001b[36m0.1914\u001b[0m       \u001b[32m0.9597\u001b[0m        \u001b[35m0.1702\u001b[0m  2.1537\n","      8        \u001b[36m0.1651\u001b[0m       \u001b[32m0.9637\u001b[0m        \u001b[35m0.1645\u001b[0m  2.7450\n","      9        \u001b[36m0.1542\u001b[0m       0.9606        0.1686  2.1985\n","     10        \u001b[36m0.1441\u001b[0m       \u001b[32m0.9641\u001b[0m        0.1724  2.2150\n","     11        \u001b[36m0.1318\u001b[0m       \u001b[32m0.9653\u001b[0m        0.1819  2.1829\n","     12        \u001b[36m0.1313\u001b[0m       0.9637        0.1879  2.2141\n","     13        \u001b[36m0.1202\u001b[0m       0.9606        0.1840  2.8298\n","     14        0.1230       \u001b[32m0.9664\u001b[0m        \u001b[35m0.1558\u001b[0m  2.2212\n","     15        \u001b[36m0.1038\u001b[0m       0.9614        0.2026  2.2632\n","     16        0.1064       0.9625        0.1954  2.2178\n","     17        \u001b[36m0.1010\u001b[0m       \u001b[32m0.9680\u001b[0m        0.1907  2.2453\n","     18        \u001b[36m0.0995\u001b[0m       0.9669        0.1753  2.7913\n","     19        \u001b[36m0.0982\u001b[0m       0.9650        0.2004  2.2305\n","     20        \u001b[36m0.0844\u001b[0m       0.9637        0.2219  2.2528\n","     21        0.0904       0.9664        0.2146  2.2347\n","     22        0.0856       \u001b[32m0.9683\u001b[0m        0.1867  2.2743\n","     23        \u001b[36m0.0810\u001b[0m       \u001b[32m0.9692\u001b[0m        0.2140  2.8617\n","     24        0.0851       0.9692        0.1926  2.2920\n","     25        0.0844       0.9677        0.2148  2.2998\n","     26        \u001b[36m0.0763\u001b[0m       0.9664        0.2066  2.3284\n","     27        \u001b[36m0.0761\u001b[0m       0.9666        0.2172  2.3268\n","     28        0.0762       0.9691        0.2050  2.9023\n","     29        \u001b[36m0.0737\u001b[0m       0.9664        0.2044  2.3447\n","     30        \u001b[36m0.0730\u001b[0m       0.9660        0.2417  2.3863\n","     31        0.0769       0.9667        0.2225  2.3972\n","     32        \u001b[36m0.0664\u001b[0m       0.9692        0.2044  2.4000\n","     33        0.0666       \u001b[32m0.9701\u001b[0m        0.2197  2.9214\n","     34        \u001b[36m0.0646\u001b[0m       0.9698        0.2358  2.3736\n","     35        \u001b[36m0.0624\u001b[0m       \u001b[32m0.9711\u001b[0m        0.2006  2.3900\n","     36        \u001b[36m0.0619\u001b[0m       0.9654        0.2522  2.3936\n","     37        0.0701       0.9679        0.2635  2.7261\n","     38        0.0653       0.9710        0.2387  2.6422\n","     39        \u001b[36m0.0594\u001b[0m       0.9691        0.2439  2.4483\n","     40        \u001b[36m0.0496\u001b[0m       0.9699        0.3067  2.4460\n","     41        0.0721       0.9700        0.2431  2.4004\n","     42        0.0535       0.9695        0.2623  2.9654\n","     43        0.0532       \u001b[32m0.9718\u001b[0m        0.2448  2.4461\n","     44        \u001b[36m0.0492\u001b[0m       0.9712        0.2530  2.4661\n","     45        0.0721       0.9673        0.2325  2.4044\n","     46        0.0532       0.9692        0.2349  2.4603\n","     47        \u001b[36m0.0488\u001b[0m       0.9701        0.2347  2.9634\n","     48        0.0511       0.9708        0.2636  2.4463\n","     49        0.0577       0.9664        0.2876  2.4766\n","     50        0.0574       0.9700        0.2863  2.4494\n","[CV] END lr=0.001, max_epochs=50, module__num_layers=3, module__num_units=128; total time= 2.0min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m1.1534\u001b[0m       \u001b[32m0.9127\u001b[0m        \u001b[35m0.3337\u001b[0m  2.4207\n","      2        \u001b[36m0.4307\u001b[0m       \u001b[32m0.9413\u001b[0m        \u001b[35m0.2276\u001b[0m  1.9361\n","      3        \u001b[36m0.3130\u001b[0m       \u001b[32m0.9454\u001b[0m        \u001b[35m0.2175\u001b[0m  1.9221\n","      4        \u001b[36m0.2600\u001b[0m       \u001b[32m0.9503\u001b[0m        \u001b[35m0.1969\u001b[0m  2.2056\n","      5        \u001b[36m0.2186\u001b[0m       \u001b[32m0.9546\u001b[0m        \u001b[35m0.1748\u001b[0m  2.1642\n","      6        \u001b[36m0.1920\u001b[0m       \u001b[32m0.9567\u001b[0m        \u001b[35m0.1704\u001b[0m  2.3128\n","      7        \u001b[36m0.1748\u001b[0m       0.9553        0.1896  2.6260\n","      8        \u001b[36m0.1692\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1577\u001b[0m  2.1568\n","      9        \u001b[36m0.1506\u001b[0m       0.9596        0.1872  2.1631\n","     10        \u001b[36m0.1491\u001b[0m       \u001b[32m0.9629\u001b[0m        0.1643  2.1807\n","     11        \u001b[36m0.1355\u001b[0m       0.9616        0.1652  2.1789\n","     12        \u001b[36m0.1344\u001b[0m       \u001b[32m0.9659\u001b[0m        \u001b[35m0.1494\u001b[0m  2.7548\n","     13        \u001b[36m0.1187\u001b[0m       0.9651        0.1572  2.1902\n","     14        \u001b[36m0.1126\u001b[0m       0.9621        0.1743  2.1872\n","     15        0.1205       \u001b[32m0.9661\u001b[0m        0.1716  2.1945\n","     16        \u001b[36m0.1068\u001b[0m       \u001b[32m0.9692\u001b[0m        0.1668  2.2121\n","     17        0.1151       0.9680        0.1552  2.8041\n","     18        \u001b[36m0.0941\u001b[0m       0.9679        0.1592  2.2269\n","     19        \u001b[36m0.0915\u001b[0m       0.9673        0.1672  2.2518\n","     20        \u001b[36m0.0903\u001b[0m       0.9639        0.1920  2.2231\n","     21        0.0931       0.9685        0.1894  2.2370\n","     22        \u001b[36m0.0857\u001b[0m       0.9673        0.1923  2.8117\n","     23        0.0927       0.9656        0.1909  2.2201\n","     24        0.0859       0.9661        0.1940  2.2347\n","     25        0.0905       0.9645        0.2146  2.2272\n","     26        \u001b[36m0.0818\u001b[0m       0.9656        0.2123  2.2512\n","     27        0.0855       0.9679        0.1915  2.8395\n","     28        0.0818       \u001b[32m0.9694\u001b[0m        0.2121  2.2606\n","     29        \u001b[36m0.0701\u001b[0m       0.9653        0.2126  2.3027\n","     30        \u001b[36m0.0640\u001b[0m       0.9669        0.2233  2.2997\n","     31        0.0723       0.9675        0.2084  2.3329\n","     32        0.0725       0.9665        0.2103  2.8964\n","     33        0.0769       0.9660        0.2183  2.3243\n","     34        0.0679       0.9677        0.2096  2.3471\n","     35        0.0648       0.9681        0.2230  2.3147\n","     36        0.0659       0.9664        0.2289  2.4600\n","     37        0.0699       0.9673        0.2276  2.7869\n","     38        0.0672       0.9649        0.2465  2.3477\n","     39        0.0701       0.9681        0.2269  2.3596\n","     40        \u001b[36m0.0608\u001b[0m       0.9691        0.2295  2.3538\n","     41        0.0627       0.9680        0.2379  2.7159\n","     42        \u001b[36m0.0607\u001b[0m       \u001b[32m0.9695\u001b[0m        0.2515  2.6126\n","     43        \u001b[36m0.0551\u001b[0m       0.9683        0.2567  2.3731\n","     44        0.0556       0.9665        0.2573  2.4187\n","     45        \u001b[36m0.0519\u001b[0m       0.9667        0.2751  2.4135\n","     46        \u001b[36m0.0487\u001b[0m       \u001b[32m0.9699\u001b[0m        0.3140  3.0007\n","     47        0.0558       0.9676        0.2985  2.4370\n","     48        0.0493       0.9690        0.3077  2.4480\n","     49        0.0674       0.9643        0.3247  2.4158\n","     50        0.0614       0.9624        0.3097  2.4307\n","[CV] END lr=0.001, max_epochs=50, module__num_layers=3, module__num_units=128; total time= 2.0min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m0.8242\u001b[0m       \u001b[32m0.9229\u001b[0m        \u001b[35m0.2810\u001b[0m  3.4299\n","      2        \u001b[36m0.3029\u001b[0m       \u001b[32m0.9390\u001b[0m        \u001b[35m0.2415\u001b[0m  3.1548\n","      3        \u001b[36m0.2308\u001b[0m       \u001b[32m0.9490\u001b[0m        \u001b[35m0.2074\u001b[0m  3.2834\n","      4        \u001b[36m0.1828\u001b[0m       \u001b[32m0.9559\u001b[0m        \u001b[35m0.1972\u001b[0m  4.4168\n","      5        \u001b[36m0.1585\u001b[0m       \u001b[32m0.9593\u001b[0m        \u001b[35m0.1757\u001b[0m  3.8009\n","      6        \u001b[36m0.1404\u001b[0m       0.9581        0.1942  3.8612\n","      7        \u001b[36m0.1379\u001b[0m       \u001b[32m0.9617\u001b[0m        0.1859  4.3864\n","      8        \u001b[36m0.1154\u001b[0m       0.9480        0.2335  3.8500\n","      9        \u001b[36m0.1102\u001b[0m       0.9605        0.2064  3.8763\n","     10        0.1110       0.9610        0.2250  4.4617\n","     11        0.1106       0.9595        0.2326  3.9674\n","     12        \u001b[36m0.0984\u001b[0m       \u001b[32m0.9631\u001b[0m        0.2224  4.0534\n","     13        \u001b[36m0.0874\u001b[0m       0.9609        0.2397  4.4900\n","     14        0.1024       0.9550        0.2416  4.0948\n","     15        0.0891       \u001b[32m0.9660\u001b[0m        0.2255  4.5613\n","     16        0.0889       0.9607        0.2547  4.2936\n","     17        \u001b[36m0.0831\u001b[0m       \u001b[32m0.9671\u001b[0m        0.2245  4.2107\n","     18        0.0902       0.9630        0.2589  4.8552\n","     19        0.0860       0.9643        0.2882  4.3551\n","     20        \u001b[36m0.0829\u001b[0m       0.9664        0.2625  4.3652\n","     21        0.0858       0.9660        0.2902  4.9351\n","     22        \u001b[36m0.0757\u001b[0m       0.9657        0.2755  4.4593\n","     23        \u001b[36m0.0704\u001b[0m       0.9635        0.3197  5.0246\n","     24        0.0743       0.9656        0.2749  4.5622\n","     25        \u001b[36m0.0670\u001b[0m       \u001b[32m0.9686\u001b[0m        0.2617  4.5788\n","     26        0.0753       0.9675        0.2687  5.0515\n","     27        0.0748       \u001b[32m0.9698\u001b[0m        0.2895  4.5523\n","     28        0.0676       0.9688        0.3086  5.1640\n","     29        \u001b[36m0.0526\u001b[0m       0.9664        0.3109  4.6597\n","     30        0.0636       0.9674        0.2962  4.7330\n","     31        0.0656       0.9677        0.3234  5.1165\n","     32        0.0636       0.9655        0.3979  4.6784\n","     33        0.0626       0.9677        0.3346  5.2904\n","     34        0.0654       0.9605        0.4360  4.7915\n","     35        0.0763       0.9681        0.3547  5.2957\n","     36        0.0636       \u001b[32m0.9699\u001b[0m        0.3989  4.8094\n","     37        0.0604       0.9676        0.4146  4.8587\n","     38        0.0653       0.9688        0.3396  5.3306\n","     39        0.0696       0.9629        0.3681  4.8071\n","     40        0.0620       0.9635        0.4625  5.3295\n","     41        0.0586       0.9686        0.3807  4.8466\n","     42        \u001b[36m0.0492\u001b[0m       0.9680        0.4104  5.3735\n","     43        0.0536       0.9688        0.4374  4.9347\n","     44        0.0540       0.9671        0.4488  4.8268\n","     45        0.0608       0.9670        0.3974  5.3444\n","     46        0.0612       0.9681        0.4285  4.8406\n","     47        \u001b[36m0.0467\u001b[0m       0.9692        0.4301  5.3660\n","     48        0.0501       0.9673        0.5132  4.8505\n","     49        0.0745       0.9666        0.5270  5.3950\n","     50        0.0673       \u001b[32m0.9700\u001b[0m        0.4650  4.8896\n","[CV] END lr=0.001, max_epochs=50, module__num_layers=3, module__num_units=256; total time= 3.9min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m0.8144\u001b[0m       \u001b[32m0.9275\u001b[0m        \u001b[35m0.2595\u001b[0m  3.1666\n","      2        \u001b[36m0.3133\u001b[0m       \u001b[32m0.9490\u001b[0m        \u001b[35m0.1946\u001b[0m  3.7776\n","      3        \u001b[36m0.2289\u001b[0m       0.9404        0.2262  3.2492\n","      4        \u001b[36m0.1999\u001b[0m       \u001b[32m0.9584\u001b[0m        \u001b[35m0.1604\u001b[0m  3.8272\n","      5        \u001b[36m0.1739\u001b[0m       \u001b[32m0.9635\u001b[0m        \u001b[35m0.1448\u001b[0m  4.3564\n","      6        \u001b[36m0.1457\u001b[0m       0.9443        0.2309  3.8244\n","      7        \u001b[36m0.1288\u001b[0m       0.9590        0.1885  3.8215\n","      8        \u001b[36m0.1212\u001b[0m       0.9620        0.1610  4.4311\n","      9        \u001b[36m0.1150\u001b[0m       0.9575        0.2005  3.8786\n","     10        \u001b[36m0.1088\u001b[0m       \u001b[32m0.9656\u001b[0m        0.1651  3.9010\n","     11        \u001b[36m0.1070\u001b[0m       0.9640        0.1711  4.4984\n","     12        \u001b[36m0.0912\u001b[0m       \u001b[32m0.9679\u001b[0m        0.1637  3.9567\n","     13        \u001b[36m0.0877\u001b[0m       0.9627        0.1905  4.0450\n","     14        \u001b[36m0.0830\u001b[0m       0.9677        0.1789  4.6592\n","     15        0.0895       \u001b[32m0.9684\u001b[0m        0.1894  4.1632\n","     16        0.1007       \u001b[32m0.9692\u001b[0m        0.1786  4.2428\n","     17        0.0901       0.9673        0.1701  4.6405\n","     18        0.0852       0.9665        0.1854  4.1871\n","     19        \u001b[36m0.0731\u001b[0m       0.9666        0.2345  4.8204\n","     20        0.0862       \u001b[32m0.9708\u001b[0m        0.1806  4.3213\n","     21        \u001b[36m0.0676\u001b[0m       0.9674        0.2184  4.4763\n","     22        0.0907       0.9694        0.1963  4.9507\n","     23        0.0718       0.9689        0.2568  4.4843\n","     24        0.0750       \u001b[32m0.9714\u001b[0m        0.1974  4.9514\n","     25        \u001b[36m0.0647\u001b[0m       0.9699        0.2157  4.6063\n","     26        0.0657       0.9700        0.2557  4.5529\n","     27        \u001b[36m0.0640\u001b[0m       0.9680        0.2610  5.0825\n","     28        0.0691       0.9680        0.2945  4.5675\n","     29        0.0710       0.9714        0.2597  5.1504\n","     30        \u001b[36m0.0583\u001b[0m       \u001b[32m0.9718\u001b[0m        0.2448  4.6447\n","     31        \u001b[36m0.0522\u001b[0m       0.9702        0.2864  4.7010\n","     32        0.0778       0.9692        0.2634  5.2377\n","     33        0.0675       \u001b[32m0.9722\u001b[0m        0.2415  4.6985\n","     34        \u001b[36m0.0504\u001b[0m       0.9699        0.3554  5.2467\n","     35        0.0628       0.9684        0.2541  4.7428\n","     36        0.1036       0.9700        0.3012  4.9210\n","     37        0.0849       \u001b[32m0.9728\u001b[0m        0.2620  5.0099\n","     38        \u001b[36m0.0493\u001b[0m       \u001b[32m0.9730\u001b[0m        0.2675  4.7507\n","     39        0.0543       0.9709        0.2592  5.2388\n","     40        0.0500       0.9715        0.2644  4.7655\n","     41        0.0543       0.9724        0.2802  5.3340\n","     42        0.0586       0.9701        0.2973  4.8460\n","     43        0.0564       0.9711        0.2967  4.7667\n","     44        \u001b[36m0.0398\u001b[0m       0.9724        0.3136  5.3248\n","     45        0.0566       0.9694        0.3385  4.8928\n","     46        0.0565       0.9720        0.3542  5.3318\n","     47        0.0618       0.9702        0.3005  4.8107\n","     48        0.0526       0.9694        0.3768  5.3287\n","     49        0.0601       0.9696        0.3519  4.7591\n","     50        0.0740       0.9720        0.3385  4.7929\n","[CV] END lr=0.001, max_epochs=50, module__num_layers=3, module__num_units=256; total time= 3.8min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m0.8042\u001b[0m       \u001b[32m0.9356\u001b[0m        \u001b[35m0.2383\u001b[0m  3.5740\n","      2        \u001b[36m0.3095\u001b[0m       \u001b[32m0.9521\u001b[0m        \u001b[35m0.1888\u001b[0m  3.1385\n","      3        \u001b[36m0.2270\u001b[0m       \u001b[32m0.9586\u001b[0m        \u001b[35m0.1588\u001b[0m  3.2616\n","      4        \u001b[36m0.1929\u001b[0m       \u001b[32m0.9623\u001b[0m        \u001b[35m0.1510\u001b[0m  4.3816\n","      5        \u001b[36m0.1517\u001b[0m       \u001b[32m0.9647\u001b[0m        \u001b[35m0.1331\u001b[0m  3.7901\n","      6        \u001b[36m0.1408\u001b[0m       0.9644        0.1453  3.8178\n","      7        \u001b[36m0.1266\u001b[0m       \u001b[32m0.9683\u001b[0m        0.1406  4.3865\n","      8        \u001b[36m0.1127\u001b[0m       0.9674        0.1582  3.8675\n","      9        \u001b[36m0.1101\u001b[0m       0.9675        0.1450  3.9146\n","     10        \u001b[36m0.0981\u001b[0m       0.9675        0.1512  4.4996\n","     11        \u001b[36m0.0932\u001b[0m       \u001b[32m0.9701\u001b[0m        0.1456  3.9271\n","     12        0.0993       \u001b[32m0.9708\u001b[0m        0.1347  4.0024\n","     13        \u001b[36m0.0780\u001b[0m       0.9636        0.1638  4.6417\n","     14        0.0888       0.9685        0.1584  4.0339\n","     15        0.0949       0.9679        0.1605  4.4911\n","     16        0.0804       0.9641        0.1822  4.3554\n","     17        0.0799       0.9708        0.1549  4.2081\n","     18        0.0885       \u001b[32m0.9711\u001b[0m        0.1615  4.7335\n","     19        0.0882       0.9711        0.1550  4.2427\n","     20        \u001b[36m0.0743\u001b[0m       0.9676        0.1854  4.2865\n","     21        0.0763       0.9683        0.1913  4.8622\n","     22        \u001b[36m0.0688\u001b[0m       0.9698        0.2022  4.3822\n","     23        0.0716       0.9654        0.2208  5.0357\n","     24        \u001b[36m0.0687\u001b[0m       0.9673        0.2171  4.4150\n","     25        \u001b[36m0.0612\u001b[0m       0.9710        0.2065  4.4701\n","     26        0.0689       0.9674        0.1998  5.0321\n","     27        0.0669       0.9706        0.1827  4.5041\n","     28        \u001b[36m0.0525\u001b[0m       0.9664        0.2128  5.0988\n","     29        0.0612       0.9686        0.2386  4.6548\n","     30        0.0821       0.9706        0.1800  4.6198\n","     31        0.0709       \u001b[32m0.9721\u001b[0m        0.2323  5.1480\n","     32        0.0670       0.9691        0.2233  4.7388\n","     33        0.0583       0.9677        0.2648  5.2511\n","     34        0.0584       \u001b[32m0.9735\u001b[0m        0.2550  4.7321\n","     35        0.0737       0.9705        0.2303  4.8519\n","     36        0.0621       0.9714        0.2856  5.2647\n","     37        0.0639       0.9731        0.2258  4.7364\n","     38        \u001b[36m0.0521\u001b[0m       \u001b[32m0.9744\u001b[0m        0.2403  5.3343\n","     39        0.0573       0.9725        0.2511  4.8293\n","     40        \u001b[36m0.0495\u001b[0m       \u001b[32m0.9751\u001b[0m        0.2058  5.3113\n","     41        0.0544       0.9732        0.2285  4.8314\n","     42        0.0765       0.9735        0.2100  4.7726\n","     43        0.0595       0.9724        0.2589  5.3224\n","     44        0.0611       0.9731        0.2443  4.8001\n","     45        0.0569       0.9715        0.2266  5.3315\n","     46        0.0547       0.9716        0.2376  4.9264\n","     47        0.0519       0.9712        0.3110  5.3998\n","     48        0.0649       0.9730        0.2663  4.9170\n","     49        0.0500       0.9741        0.2940  4.8812\n","     50        0.0517       0.9716        0.2736  5.3753\n","[CV] END lr=0.001, max_epochs=50, module__num_layers=3, module__num_units=256; total time= 3.8min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m1.7508\u001b[0m       \u001b[32m0.6770\u001b[0m        \u001b[35m1.0137\u001b[0m  2.1863\n","      2        \u001b[36m0.8888\u001b[0m       \u001b[32m0.8075\u001b[0m        \u001b[35m0.6508\u001b[0m  2.2078\n","      3        \u001b[36m0.6117\u001b[0m       \u001b[32m0.8734\u001b[0m        \u001b[35m0.5136\u001b[0m  2.7396\n","      4        \u001b[36m0.5053\u001b[0m       \u001b[32m0.8826\u001b[0m        \u001b[35m0.4572\u001b[0m  2.6622\n","      5        \u001b[36m0.4270\u001b[0m       \u001b[32m0.9105\u001b[0m        \u001b[35m0.3710\u001b[0m  2.5487\n","      6        \u001b[36m0.3729\u001b[0m       \u001b[32m0.9211\u001b[0m        0.3750  2.5736\n","      7        \u001b[36m0.3361\u001b[0m       \u001b[32m0.9266\u001b[0m        \u001b[35m0.3459\u001b[0m  2.6118\n","      8        \u001b[36m0.2846\u001b[0m       \u001b[32m0.9340\u001b[0m        \u001b[35m0.3185\u001b[0m  3.1566\n","      9        \u001b[36m0.2736\u001b[0m       \u001b[32m0.9419\u001b[0m        \u001b[35m0.2916\u001b[0m  2.5770\n","     10        \u001b[36m0.2450\u001b[0m       0.9376        0.2923  2.6114\n","     11        \u001b[36m0.2305\u001b[0m       0.9411        0.3096  2.6123\n","     12        \u001b[36m0.2144\u001b[0m       \u001b[32m0.9457\u001b[0m        \u001b[35m0.2815\u001b[0m  3.1897\n","     13        \u001b[36m0.2099\u001b[0m       0.9457        0.2921  2.6126\n","     14        \u001b[36m0.2011\u001b[0m       \u001b[32m0.9486\u001b[0m        \u001b[35m0.2748\u001b[0m  2.6071\n","     15        \u001b[36m0.2000\u001b[0m       0.9467        0.2775  2.5834\n","     16        \u001b[36m0.1847\u001b[0m       0.9471        0.3070  3.0842\n","     17        \u001b[36m0.1745\u001b[0m       0.9476        0.3529  2.7614\n","     18        0.1769       \u001b[32m0.9496\u001b[0m        0.3107  2.6146\n","     19        \u001b[36m0.1607\u001b[0m       \u001b[32m0.9497\u001b[0m        0.3017  2.6363\n","     20        0.1627       0.9484        0.3052  2.7694\n","     21        \u001b[36m0.1558\u001b[0m       \u001b[32m0.9529\u001b[0m        0.3003  3.1001\n","     22        0.1613       0.9523        0.3052  2.6278\n","     23        \u001b[36m0.1423\u001b[0m       0.9524        0.3368  2.6396\n","     24        0.1562       0.9519        0.2946  2.6502\n","     25        0.1493       0.9506        0.3190  3.2230\n","     26        0.1495       0.9529        0.3020  2.6584\n","     27        0.1505       0.9529        0.3445  2.6626\n","     28        \u001b[36m0.1356\u001b[0m       \u001b[32m0.9546\u001b[0m        0.3011  2.6986\n","     29        0.1357       0.9494        0.3186  3.2165\n","     30        \u001b[36m0.1255\u001b[0m       \u001b[32m0.9549\u001b[0m        0.3370  2.6893\n","     31        0.1304       0.9543        0.3358  2.7159\n","     32        0.1362       0.9515        0.3291  2.7046\n","     33        0.1330       0.9527        0.3573  3.2649\n","     34        0.1307       0.9539        0.3254  2.6732\n","     35        0.1316       0.9535        0.3250  2.7225\n","     36        \u001b[36m0.1248\u001b[0m       0.9534        0.3263  2.7023\n","     37        \u001b[36m0.1209\u001b[0m       0.9534        0.3947  3.1051\n","     38        \u001b[36m0.1144\u001b[0m       0.9537        0.3589  2.9139\n","     39        \u001b[36m0.1092\u001b[0m       \u001b[32m0.9576\u001b[0m        0.3256  2.7822\n","     40        0.1180       \u001b[32m0.9577\u001b[0m        0.3225  2.7381\n","     41        0.1132       0.9569        0.3390  2.9836\n","     42        0.1188       0.9543        0.3691  3.0384\n","     43        0.1142       0.9563        0.3443  2.7474\n","     44        0.1108       0.9561        0.3597  2.7139\n","     45        0.1097       0.9559        0.3521  2.8644\n","     46        0.1133       0.9561        0.3636  3.1621\n","     47        0.1136       0.9531        0.3348  2.7301\n","     48        \u001b[36m0.0976\u001b[0m       0.9519        0.3903  2.7505\n","     49        0.1184       0.9567        0.3410  2.7531\n","     50        0.1032       \u001b[32m0.9589\u001b[0m        0.2976  3.3283\n","[CV] END lr=0.001, max_epochs=50, module__num_layers=5, module__num_units=128; total time= 2.3min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m1.6315\u001b[0m       \u001b[32m0.7412\u001b[0m        \u001b[35m0.7275\u001b[0m  2.2126\n","      2        \u001b[36m0.7652\u001b[0m       \u001b[32m0.8083\u001b[0m        \u001b[35m0.5860\u001b[0m  2.2115\n","      3        \u001b[36m0.6035\u001b[0m       \u001b[32m0.8568\u001b[0m        \u001b[35m0.4391\u001b[0m  2.2907\n","      4        \u001b[36m0.4983\u001b[0m       \u001b[32m0.8781\u001b[0m        \u001b[35m0.3927\u001b[0m  3.1439\n","      5        \u001b[36m0.4371\u001b[0m       \u001b[32m0.9323\u001b[0m        \u001b[35m0.2895\u001b[0m  2.5422\n","      6        \u001b[36m0.3570\u001b[0m       0.9205        0.3738  2.5347\n","      7        \u001b[36m0.3078\u001b[0m       \u001b[32m0.9365\u001b[0m        0.3445  2.5486\n","      8        \u001b[36m0.2758\u001b[0m       \u001b[32m0.9499\u001b[0m        \u001b[35m0.2306\u001b[0m  2.7516\n","      9        \u001b[36m0.2517\u001b[0m       0.9454        0.2724  2.9914\n","     10        \u001b[36m0.2352\u001b[0m       \u001b[32m0.9517\u001b[0m        0.2478  2.5641\n","     11        \u001b[36m0.2052\u001b[0m       \u001b[32m0.9546\u001b[0m        \u001b[35m0.2254\u001b[0m  2.6204\n","     12        \u001b[36m0.1999\u001b[0m       0.9521        0.2521  2.5806\n","     13        \u001b[36m0.1889\u001b[0m       0.9509        0.2663  3.1871\n","     14        0.1894       0.9510        0.2337  2.5888\n","     15        0.1942       \u001b[32m0.9577\u001b[0m        \u001b[35m0.2198\u001b[0m  2.6117\n","     16        \u001b[36m0.1723\u001b[0m       \u001b[32m0.9583\u001b[0m        0.2262  2.6349\n","     17        \u001b[36m0.1688\u001b[0m       \u001b[32m0.9590\u001b[0m        \u001b[35m0.2146\u001b[0m  3.2473\n","     18        \u001b[36m0.1613\u001b[0m       0.9566        0.2259  2.6624\n","     19        \u001b[36m0.1470\u001b[0m       0.9576        0.2338  2.6688\n","     20        \u001b[36m0.1448\u001b[0m       \u001b[32m0.9601\u001b[0m        0.2183  2.6538\n","     21        \u001b[36m0.1377\u001b[0m       \u001b[32m0.9614\u001b[0m        0.2507  2.9958\n","     22        0.1441       0.9581        0.2490  2.9260\n","     23        \u001b[36m0.1366\u001b[0m       0.9577        0.2559  2.6892\n","     24        0.1483       \u001b[32m0.9634\u001b[0m        \u001b[35m0.2071\u001b[0m  2.6551\n","     25        \u001b[36m0.1334\u001b[0m       0.9559        0.2692  2.7478\n","     26        0.1349       \u001b[32m0.9653\u001b[0m        0.2231  3.1586\n","     27        0.1375       0.9626        0.2183  2.7110\n","     28        0.1378       0.9593        0.2205  2.6971\n","     29        \u001b[36m0.1269\u001b[0m       0.9607        0.2214  2.7060\n","     30        0.1378       0.9641        0.2205  3.2797\n","     31        \u001b[36m0.1135\u001b[0m       0.9636        0.2366  2.7422\n","     32        0.1210       0.9629        0.2376  2.7280\n","     33        \u001b[36m0.1131\u001b[0m       0.9653        \u001b[35m0.2037\u001b[0m  2.7378\n","     34        0.1210       0.9629        0.2146  3.2740\n","     35        0.1227       0.9573        0.2464  2.6997\n","     36        \u001b[36m0.1106\u001b[0m       0.9649        0.2420  2.7190\n","     37        \u001b[36m0.1098\u001b[0m       0.9644        0.2657  2.7617\n","     38        \u001b[36m0.1084\u001b[0m       0.9629        0.2352  3.3157\n","     39        \u001b[36m0.1067\u001b[0m       0.9626        0.2892  2.7173\n","     40        0.1130       0.9605        0.2948  2.7570\n","     41        0.1212       \u001b[32m0.9666\u001b[0m        0.2398  2.7544\n","     42        0.1141       0.9631        0.2385  3.3062\n","     43        0.1093       0.9654        0.2617  2.7629\n","     44        \u001b[36m0.1009\u001b[0m       \u001b[32m0.9680\u001b[0m        0.2083  2.7746\n","     45        \u001b[36m0.0940\u001b[0m       0.9666        0.2448  2.7968\n","     46        0.1016       0.9649        0.2408  3.3772\n","     47        0.0950       0.9670        0.2536  2.7900\n","     48        0.1010       0.9576        0.2595  2.8241\n","     49        0.1245       0.9614        0.2420  2.7887\n","     50        0.1077       0.9625        0.2068  3.3806\n","[CV] END lr=0.001, max_epochs=50, module__num_layers=5, module__num_units=128; total time= 2.3min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m1.6993\u001b[0m       \u001b[32m0.6983\u001b[0m        \u001b[35m0.8596\u001b[0m  2.2047\n","      2        \u001b[36m0.7625\u001b[0m       \u001b[32m0.8542\u001b[0m        \u001b[35m0.4402\u001b[0m  2.2192\n","      3        \u001b[36m0.5153\u001b[0m       \u001b[32m0.9186\u001b[0m        \u001b[35m0.3350\u001b[0m  2.3168\n","      4        \u001b[36m0.4078\u001b[0m       \u001b[32m0.9356\u001b[0m        \u001b[35m0.2696\u001b[0m  2.6463\n","      5        \u001b[36m0.3349\u001b[0m       \u001b[32m0.9400\u001b[0m        \u001b[35m0.2424\u001b[0m  3.1132\n","      6        \u001b[36m0.2913\u001b[0m       \u001b[32m0.9449\u001b[0m        0.2461  2.5749\n","      7        \u001b[36m0.2841\u001b[0m       \u001b[32m0.9494\u001b[0m        \u001b[35m0.2230\u001b[0m  2.5739\n","      8        \u001b[36m0.2511\u001b[0m       \u001b[32m0.9504\u001b[0m        \u001b[35m0.2172\u001b[0m  2.5594\n","      9        \u001b[36m0.2483\u001b[0m       0.9481        0.2296  3.1713\n","     10        \u001b[36m0.2304\u001b[0m       0.9464        0.2491  2.6070\n","     11        \u001b[36m0.2115\u001b[0m       \u001b[32m0.9523\u001b[0m        \u001b[35m0.2156\u001b[0m  2.5840\n","     12        0.2128       0.9507        0.2314  2.6229\n","     13        \u001b[36m0.2113\u001b[0m       0.9495        0.2299  3.0244\n","     14        \u001b[36m0.2016\u001b[0m       0.9510        \u001b[35m0.2090\u001b[0m  2.7453\n","     15        \u001b[36m0.1838\u001b[0m       0.9450        0.2318  2.6259\n","     16        0.1843       \u001b[32m0.9530\u001b[0m        0.2146  2.5816\n","     17        \u001b[36m0.1742\u001b[0m       0.9524        0.2529  2.6524\n","     18        \u001b[36m0.1705\u001b[0m       0.9501        0.2503  3.1381\n","     19        \u001b[36m0.1678\u001b[0m       \u001b[32m0.9555\u001b[0m        0.2254  2.6509\n","     20        \u001b[36m0.1576\u001b[0m       0.9551        0.2314  2.6224\n","     21        \u001b[36m0.1560\u001b[0m       0.9535        0.2238  2.6602\n","     22        \u001b[36m0.1545\u001b[0m       \u001b[32m0.9579\u001b[0m        0.2176  3.2235\n","     23        \u001b[36m0.1459\u001b[0m       0.9571        0.2133  2.6782\n","     24        0.1508       0.9527        0.2302  2.6521\n","     25        \u001b[36m0.1432\u001b[0m       0.9514        0.2748  2.6587\n","     26        0.1495       0.9577        0.2352  3.2410\n","     27        \u001b[36m0.1367\u001b[0m       0.9571        0.2197  2.6613\n","     28        0.1374       0.9519        0.2395  2.6489\n","     29        0.1517       \u001b[32m0.9600\u001b[0m        0.2143  2.6703\n","     30        \u001b[36m0.1353\u001b[0m       0.9577        0.2558  3.0971\n","     31        \u001b[36m0.1338\u001b[0m       0.9559        0.2302  2.8230\n","     32        0.1427       0.9525        0.2435  2.6578\n","     33        \u001b[36m0.1336\u001b[0m       0.9513        0.2680  2.6738\n","     34        0.1400       0.9567        0.2255  2.8604\n","     35        \u001b[36m0.1286\u001b[0m       0.9573        0.2296  3.0768\n","     36        \u001b[36m0.1233\u001b[0m       0.9560        0.2644  2.6995\n","     37        0.1249       0.9560        0.2364  2.6882\n","     38        \u001b[36m0.1165\u001b[0m       0.9589        0.2616  2.7227\n","     39        0.1282       0.9560        0.2209  3.3153\n","     40        0.1302       0.9599        0.2342  2.6645\n","     41        0.1282       \u001b[32m0.9620\u001b[0m        0.2251  2.6779\n","     42        \u001b[36m0.1070\u001b[0m       0.9610        0.2279  2.7381\n","     43        0.1182       0.9603        0.2293  3.2999\n","     44        \u001b[36m0.1037\u001b[0m       0.9609        0.2342  2.7358\n","     45        0.1118       0.9587        0.2472  2.7030\n","     46        0.1141       0.9570        0.2473  2.7008\n","     47        0.1055       0.9599        0.2286  3.3051\n","     48        0.1052       0.9583        0.2466  2.7135\n","     49        0.1106       0.9591        0.2331  2.6911\n","     50        0.1145       0.9554        0.3338  2.7046\n","[CV] END lr=0.001, max_epochs=50, module__num_layers=5, module__num_units=128; total time= 2.3min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m1.2680\u001b[0m       \u001b[32m0.8812\u001b[0m        \u001b[35m0.4989\u001b[0m  4.6855\n","      2        \u001b[36m0.4030\u001b[0m       \u001b[32m0.9390\u001b[0m        \u001b[35m0.2943\u001b[0m  4.0280\n","      3        \u001b[36m0.2789\u001b[0m       \u001b[32m0.9511\u001b[0m        \u001b[35m0.2362\u001b[0m  4.4095\n","      4        \u001b[36m0.2278\u001b[0m       \u001b[32m0.9525\u001b[0m        0.2412  5.2613\n","      5        \u001b[36m0.1983\u001b[0m       \u001b[32m0.9537\u001b[0m        0.2617  4.8240\n","      6        \u001b[36m0.1840\u001b[0m       \u001b[32m0.9553\u001b[0m        0.2376  5.4708\n","      7        \u001b[36m0.1607\u001b[0m       0.9525        0.2652  4.8915\n","      8        0.1668       \u001b[32m0.9610\u001b[0m        \u001b[35m0.2090\u001b[0m  5.4533\n","      9        \u001b[36m0.1445\u001b[0m       \u001b[32m0.9613\u001b[0m        0.2587  4.9610\n","     10        \u001b[36m0.1284\u001b[0m       0.9571        0.2582  5.4193\n","     11        \u001b[36m0.1279\u001b[0m       \u001b[32m0.9633\u001b[0m        0.2466  5.2694\n","     12        \u001b[36m0.1226\u001b[0m       \u001b[32m0.9664\u001b[0m        0.2478  5.1029\n","     13        \u001b[36m0.1142\u001b[0m       0.9664        0.2303  5.6720\n","     14        \u001b[36m0.1131\u001b[0m       0.9623        0.2826  5.1970\n","     15        \u001b[36m0.1097\u001b[0m       0.9616        0.2713  5.7799\n","     16        0.1118       0.9637        0.3082  5.3191\n","     17        \u001b[36m0.0974\u001b[0m       0.9613        0.2883  5.9430\n","     18        0.1106       0.9647        0.2672  5.3545\n","     19        \u001b[36m0.0953\u001b[0m       \u001b[32m0.9670\u001b[0m        0.2510  5.9588\n","     20        0.0985       \u001b[32m0.9677\u001b[0m        0.2895  5.5175\n","     21        0.0987       0.9630        0.2440  6.0728\n","     22        0.1007       0.9641        0.2868  5.4182\n","     23        \u001b[36m0.0898\u001b[0m       0.9670        0.2422  6.0567\n","     24        \u001b[36m0.0809\u001b[0m       0.9671        0.2853  5.6584\n","     25        0.1009       0.9645        0.3102  6.1873\n","     26        0.0928       \u001b[32m0.9694\u001b[0m        0.3028  5.6735\n","     27        0.0816       0.9674        0.3061  6.3014\n","     28        0.0815       0.9671        0.3220  5.7756\n","     29        0.0866       0.9667        0.3454  6.3267\n","     30        \u001b[36m0.0703\u001b[0m       0.9649        0.3237  5.8815\n","     31        0.0897       0.9660        0.3873  6.3317\n","     32        0.0840       0.9675        0.3186  5.7968\n","     33        0.0866       0.9653        0.3374  6.2965\n","     34        0.0750       0.9637        0.3372  5.7796\n","     35        0.0866       0.9694        0.3217  6.3097\n","     36        \u001b[36m0.0674\u001b[0m       0.9651        0.3730  5.8269\n","     37        0.0834       0.9666        0.3716  6.3966\n","     38        0.0985       0.9633        0.4306  5.8274\n","     39        0.0967       0.9692        0.3199  6.4013\n","     40        0.0722       0.9663        0.3210  5.9361\n","     41        0.0727       \u001b[32m0.9710\u001b[0m        0.3498  6.4809\n","     42        \u001b[36m0.0673\u001b[0m       0.9630        0.3867  5.9569\n","     43        0.0851       0.9661        0.3088  6.4230\n","     44        \u001b[36m0.0616\u001b[0m       0.9669        0.3430  6.0349\n","     45        0.0683       0.9679        0.3609  6.4445\n","     46        0.0623       \u001b[32m0.9730\u001b[0m        0.4056  6.4344\n","     47        0.0764       0.9671        0.4494  6.1711\n","     48        0.0873       0.9688        0.4314  6.5261\n","     49        0.0742       0.9696        0.4717  6.0169\n","     50        0.0856       0.9673        0.3448  6.4466\n","[CV] END lr=0.001, max_epochs=50, module__num_layers=5, module__num_units=256; total time= 4.8min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m1.1540\u001b[0m       \u001b[32m0.9034\u001b[0m        \u001b[35m0.3784\u001b[0m  4.0501\n","      2        \u001b[36m0.3934\u001b[0m       \u001b[32m0.9234\u001b[0m        \u001b[35m0.3517\u001b[0m  4.0683\n","      3        \u001b[36m0.2921\u001b[0m       \u001b[32m0.9465\u001b[0m        \u001b[35m0.2563\u001b[0m  4.8037\n","      4        \u001b[36m0.2225\u001b[0m       \u001b[32m0.9545\u001b[0m        \u001b[35m0.2081\u001b[0m  4.7764\n","      5        \u001b[36m0.2050\u001b[0m       \u001b[32m0.9555\u001b[0m        0.2178  5.3574\n","      6        \u001b[36m0.1787\u001b[0m       \u001b[32m0.9605\u001b[0m        \u001b[35m0.1917\u001b[0m  4.8218\n","      7        \u001b[36m0.1516\u001b[0m       \u001b[32m0.9640\u001b[0m        0.1922  5.2041\n","      8        0.1553       0.9634        0.1943  5.1453\n","      9        \u001b[36m0.1382\u001b[0m       \u001b[32m0.9660\u001b[0m        \u001b[35m0.1868\u001b[0m  4.9320\n","     10        \u001b[36m0.1269\u001b[0m       0.9645        0.2051  5.5877\n","     11        0.1362       0.9651        \u001b[35m0.1712\u001b[0m  5.0117\n","     12        \u001b[36m0.1097\u001b[0m       \u001b[32m0.9677\u001b[0m        0.1959  5.6666\n","     13        0.1133       0.9677        0.1892  5.1596\n","     14        \u001b[36m0.1034\u001b[0m       0.9673        0.2129  5.7594\n","     15        \u001b[36m0.0890\u001b[0m       0.9674        0.2130  5.2611\n","     16        0.1126       0.9639        0.1947  5.8088\n","     17        0.1014       0.9670        0.2275  5.3128\n","     18        0.1005       0.9654        0.2144  5.7292\n","     19        0.0973       \u001b[32m0.9696\u001b[0m        0.1901  5.5049\n","     20        \u001b[36m0.0800\u001b[0m       0.9689        0.2091  5.6087\n","     21        0.0830       0.9696        0.2316  5.8550\n","     22        0.1002       0.9663        0.2283  5.4369\n","     23        0.0937       0.9685        0.2177  6.0302\n","     24        0.0939       0.9667        0.2479  5.5637\n","     25        0.0905       0.9684        0.2146  6.1059\n","     26        0.0988       0.9669        0.2183  5.5375\n","     27        \u001b[36m0.0751\u001b[0m       0.9686        0.2699  6.1711\n","     28        0.0889       0.9694        0.2715  5.5856\n","     29        \u001b[36m0.0635\u001b[0m       \u001b[32m0.9708\u001b[0m        0.2536  6.2399\n","     30        0.0718       0.9674        0.2682  5.7554\n","     31        0.0676       0.9704        0.2452  6.3399\n","     32        0.0688       0.9702        0.2769  5.7845\n","     33        \u001b[36m0.0620\u001b[0m       \u001b[32m0.9722\u001b[0m        0.2714  6.3618\n","     34        0.0814       0.9666        0.2991  5.9282\n","     35        0.0777       0.9706        0.2825  6.1362\n","     36        0.0630       0.9698        0.2197  6.0129\n","     37        0.0625       0.9690        0.2569  6.2433\n","     38        0.0728       0.9676        0.2931  6.2090\n","     39        0.0785       0.9716        0.2254  5.9923\n","     40        0.0679       0.9679        0.2352  6.4405\n","     41        0.0648       0.9709        0.2398  5.8795\n","     42        \u001b[36m0.0569\u001b[0m       0.9666        0.3271  6.5211\n","     43        0.0860       0.9649        0.2770  5.9708\n","     44        0.0669       0.9705        0.2346  6.4821\n","     45        0.0603       0.9702        0.2305  5.9956\n","     46        0.0638       0.9711        0.2567  6.5325\n","     47        0.0740       0.9679        0.2504  5.9332\n","     48        0.0619       0.9705        0.2458  6.4752\n","     49        \u001b[36m0.0505\u001b[0m       0.9698        0.3179  6.0812\n","     50        0.0572       0.9696        0.3262  6.6070\n","[CV] END lr=0.001, max_epochs=50, module__num_layers=5, module__num_units=256; total time= 4.8min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m1.2111\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.4533\u001b[0m  4.0192\n","      2        \u001b[36m0.4147\u001b[0m       \u001b[32m0.9465\u001b[0m        \u001b[35m0.2174\u001b[0m  4.6999\n","      3        \u001b[36m0.2849\u001b[0m       \u001b[32m0.9564\u001b[0m        \u001b[35m0.1933\u001b[0m  4.1919\n","      4        \u001b[36m0.2358\u001b[0m       \u001b[32m0.9580\u001b[0m        \u001b[35m0.1809\u001b[0m  4.7643\n","      5        \u001b[36m0.2071\u001b[0m       \u001b[32m0.9600\u001b[0m        0.1850  5.3873\n","      6        \u001b[36m0.1780\u001b[0m       \u001b[32m0.9634\u001b[0m        \u001b[35m0.1639\u001b[0m  4.7883\n","      7        \u001b[36m0.1598\u001b[0m       0.9634        0.1714  5.4249\n","      8        \u001b[36m0.1531\u001b[0m       0.9627        0.1698  4.8427\n","      9        \u001b[36m0.1377\u001b[0m       \u001b[32m0.9670\u001b[0m        0.1704  5.4210\n","     10        \u001b[36m0.1359\u001b[0m       0.9657        0.1879  4.9106\n","     11        0.1393       0.9624        0.1869  5.0595\n","     12        \u001b[36m0.1235\u001b[0m       0.9656        0.1792  5.5372\n","     13        0.1328       \u001b[32m0.9671\u001b[0m        0.1747  5.0761\n","     14        0.1239       0.9644        0.1927  5.6594\n","     15        \u001b[36m0.1078\u001b[0m       0.9631        0.1999  5.1373\n","     16        \u001b[36m0.1019\u001b[0m       \u001b[32m0.9676\u001b[0m        0.1976  5.8417\n","     17        \u001b[36m0.1015\u001b[0m       0.9671        0.2269  5.2883\n","     18        0.1030       0.9667        0.1851  5.7676\n","     19        \u001b[36m0.0980\u001b[0m       0.9676        0.2001  5.2738\n","     20        0.1066       0.9670        0.2159  5.8804\n","     21        \u001b[36m0.0782\u001b[0m       \u001b[32m0.9710\u001b[0m        0.1971  5.3732\n","     22        \u001b[36m0.0770\u001b[0m       0.9674        0.2064  6.1233\n","     23        0.0918       0.9680        0.1879  5.5135\n","     24        0.0923       0.9650        0.2167  6.1792\n","     25        0.0783       0.9683        0.2143  5.6848\n","     26        0.0990       0.9677        0.2115  6.2431\n","     27        0.0913       0.9701        0.2043  5.6618\n","     28        0.0790       0.9698        0.2075  6.2705\n","     29        0.0816       0.9705        0.1916  5.7250\n","     30        \u001b[36m0.0726\u001b[0m       0.9673        0.2432  6.2527\n","     31        0.0753       0.9684        0.2164  5.8125\n","     32        0.0734       \u001b[32m0.9718\u001b[0m        0.2301  6.3532\n","     33        0.0817       0.9681        0.2223  5.7412\n","     34        0.0799       0.9706        0.2283  6.3206\n","     35        0.0789       0.9692        0.2219  5.8457\n","     36        \u001b[36m0.0709\u001b[0m       0.9698        0.2312  6.4295\n","     37        0.0728       0.9709        0.2609  5.8106\n","     38        0.0741       0.9711        0.2647  6.3388\n","     39        0.0848       0.9673        0.2189  5.9021\n","     40        0.0710       0.9688        0.2500  6.4391\n","     41        0.0899       0.9664        0.2151  5.8542\n","     42        0.0757       0.9702        0.2424  6.3978\n","     43        0.0838       0.9704        0.2389  5.9180\n","     44        0.0746       0.9691        0.2656  6.4324\n","     45        0.0791       0.9673        0.2247  5.8414\n","     46        \u001b[36m0.0664\u001b[0m       0.9708        0.2804  6.4670\n","     47        \u001b[36m0.0552\u001b[0m       0.9715        0.3092  6.0232\n","     48        0.1042       0.9629        0.2408  6.4415\n","     49        0.0772       0.9712        0.2198  5.9240\n","     50        0.0827       0.9695        0.2118  6.4292\n","[CV] END lr=0.001, max_epochs=50, module__num_layers=5, module__num_units=256; total time= 4.8min\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.1423\u001b[0m       \u001b[32m0.4681\u001b[0m        \u001b[35m1.4303\u001b[0m  6.6618\n","      2        \u001b[36m1.0654\u001b[0m       \u001b[32m0.8579\u001b[0m        \u001b[35m0.4776\u001b[0m  6.0317\n","      3        \u001b[36m0.5551\u001b[0m       \u001b[32m0.9343\u001b[0m        \u001b[35m0.2546\u001b[0m  6.8111\n","      4        \u001b[36m0.3653\u001b[0m       \u001b[32m0.9484\u001b[0m        \u001b[35m0.2011\u001b[0m  6.2115\n","      5        \u001b[36m0.2791\u001b[0m       \u001b[32m0.9537\u001b[0m        \u001b[35m0.1749\u001b[0m  6.8152\n","      6        \u001b[36m0.2302\u001b[0m       \u001b[32m0.9589\u001b[0m        \u001b[35m0.1611\u001b[0m  6.2234\n","      7        \u001b[36m0.1925\u001b[0m       \u001b[32m0.9613\u001b[0m        \u001b[35m0.1537\u001b[0m  6.8137\n","      8        \u001b[36m0.1610\u001b[0m       \u001b[32m0.9660\u001b[0m        \u001b[35m0.1435\u001b[0m  6.2032\n","      9        \u001b[36m0.1432\u001b[0m       \u001b[32m0.9684\u001b[0m        \u001b[35m0.1383\u001b[0m  6.7929\n","     10        \u001b[36m0.1319\u001b[0m       \u001b[32m0.9687\u001b[0m        \u001b[35m0.1328\u001b[0m  6.5714\n","     11        \u001b[36m0.1127\u001b[0m       \u001b[32m0.9710\u001b[0m        0.1339  6.5440\n","     12        \u001b[36m0.1057\u001b[0m       \u001b[32m0.9719\u001b[0m        0.1344  6.8417\n","     13        \u001b[36m0.0917\u001b[0m       0.9710        0.1407  6.2746\n","     14        \u001b[36m0.0835\u001b[0m       \u001b[32m0.9729\u001b[0m        \u001b[35m0.1307\u001b[0m  6.8478\n","     15        \u001b[36m0.0747\u001b[0m       0.9718        0.1427  6.2667\n","     16        \u001b[36m0.0701\u001b[0m       \u001b[32m0.9738\u001b[0m        0.1366  6.9249\n","     17        \u001b[36m0.0667\u001b[0m       \u001b[32m0.9742\u001b[0m        0.1361  6.3160\n","     18        \u001b[36m0.0616\u001b[0m       0.9732        0.1358  6.9505\n","     19        \u001b[36m0.0564\u001b[0m       \u001b[32m0.9752\u001b[0m        0.1405  6.8220\n","     20        \u001b[36m0.0514\u001b[0m       0.9750        0.1338  6.5386\n","     21        \u001b[36m0.0474\u001b[0m       0.9746        0.1436  7.0184\n","     22        \u001b[36m0.0444\u001b[0m       \u001b[32m0.9769\u001b[0m        0.1498  6.4628\n","     23        \u001b[36m0.0397\u001b[0m       0.9768        0.1469  7.0760\n","     24        \u001b[36m0.0358\u001b[0m       0.9759        0.1441  6.5386\n","     25        0.0372       \u001b[32m0.9772\u001b[0m        0.1437  7.1436\n","     26        \u001b[36m0.0335\u001b[0m       0.9762        0.1571  7.2145\n","     27        \u001b[36m0.0312\u001b[0m       \u001b[32m0.9774\u001b[0m        0.1500  6.7099\n","     28        0.0345       0.9761        0.1633  7.3187\n","     29        \u001b[36m0.0283\u001b[0m       0.9758        0.1675  6.7308\n","     30        0.0295       \u001b[32m0.9778\u001b[0m        0.1506  7.3387\n","     31        \u001b[36m0.0274\u001b[0m       0.9770        0.1603  7.2341\n","     32        \u001b[36m0.0269\u001b[0m       0.9775        0.1494  6.9068\n","     33        \u001b[36m0.0238\u001b[0m       0.9775        0.1532  7.4625\n","     34        \u001b[36m0.0228\u001b[0m       0.9764        0.1734  6.8185\n","     35        0.0246       0.9772        0.1682  7.4241\n","     36        \u001b[36m0.0189\u001b[0m       \u001b[32m0.9779\u001b[0m        0.1555  7.5771\n","     37        0.0229       \u001b[32m0.9788\u001b[0m        0.1567  7.0326\n","     38        0.0209       0.9772        0.1646  7.5525\n","     39        0.0197       \u001b[32m0.9790\u001b[0m        0.1747  7.1085\n","     40        0.0217       0.9784        0.1588  7.5853\n","     41        \u001b[36m0.0183\u001b[0m       0.9777        0.1722  7.7072\n","     42        \u001b[36m0.0168\u001b[0m       0.9786        0.1753  7.2331\n","     43        0.0174       0.9784        0.1775  7.8424\n","     44        0.0175       \u001b[32m0.9791\u001b[0m        0.1706  7.7787\n","     45        \u001b[36m0.0149\u001b[0m       0.9761        0.1921  7.2604\n","     46        0.0201       0.9789        0.1491  7.7969\n","     47        \u001b[36m0.0130\u001b[0m       0.9770        0.1786  7.7923\n","     48        0.0164       0.9775        0.1735  7.3521\n","     49        0.0139       0.9781        0.1760  8.0280\n","     50        \u001b[36m0.0120\u001b[0m       \u001b[32m0.9803\u001b[0m        0.1727  7.8535\n"]},{"data":{"text/html":["\u003cstyle\u003e#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}\u003c/style\u003e\u003cdiv id=\"sk-container-id-1\" class=\"sk-top-container\"\u003e\u003cdiv class=\"sk-text-repr-fallback\"\u003e\u003cpre\u003eGridSearchCV(cv=3,\n","             estimator=\u0026lt;class \u0026#x27;skorch.classifier.NeuralNetClassifier\u0026#x27;\u0026gt;[uninitialized](\n","  module=MLP(\n","    (flatten): Flatten(start_dim=1, end_dim=-1)\n","    (input_layer): Linear(in_features=784, out_features=128, bias=True)\n","    (relu): ReLU()\n","    (hidden_layers): ModuleList(\n","      (0-9): 10 x Linear(in_features=128, out_features=128, bias=True)\n","    )\n","    (output_layer): Linear(in_features=128, out_features=10, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  ),\n","),\n","             param_grid={\u0026#x27;lr\u0026#x27;: [0.0001, 0.001], \u0026#x27;max_epochs\u0026#x27;: [50],\n","                         \u0026#x27;module__num_layers\u0026#x27;: [3, 5],\n","                         \u0026#x27;module__num_units\u0026#x27;: [128, 256]},\n","             verbose=2)\u003c/pre\u003e\u003cb\u003eIn a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. \u003cbr /\u003eOn GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\u003c/b\u003e\u003c/div\u003e\u003cdiv class=\"sk-container\" hidden\u003e\u003cdiv class=\"sk-item sk-dashed-wrapped\"\u003e\u003cdiv class=\"sk-label-container\"\u003e\u003cdiv class=\"sk-label sk-toggleable\"\u003e\u003cinput class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" \u003e\u003clabel for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\"\u003eGridSearchCV\u003c/label\u003e\u003cdiv class=\"sk-toggleable__content\"\u003e\u003cpre\u003eGridSearchCV(cv=3,\n","             estimator=\u0026lt;class \u0026#x27;skorch.classifier.NeuralNetClassifier\u0026#x27;\u0026gt;[uninitialized](\n","  module=MLP(\n","    (flatten): Flatten(start_dim=1, end_dim=-1)\n","    (input_layer): Linear(in_features=784, out_features=128, bias=True)\n","    (relu): ReLU()\n","    (hidden_layers): ModuleList(\n","      (0-9): 10 x Linear(in_features=128, out_features=128, bias=True)\n","    )\n","    (output_layer): Linear(in_features=128, out_features=10, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  ),\n","),\n","             param_grid={\u0026#x27;lr\u0026#x27;: [0.0001, 0.001], \u0026#x27;max_epochs\u0026#x27;: [50],\n","                         \u0026#x27;module__num_layers\u0026#x27;: [3, 5],\n","                         \u0026#x27;module__num_units\u0026#x27;: [128, 256]},\n","             verbose=2)\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"sk-parallel\"\u003e\u003cdiv class=\"sk-parallel-item\"\u003e\u003cdiv class=\"sk-item\"\u003e\u003cdiv class=\"sk-label-container\"\u003e\u003cdiv class=\"sk-label sk-toggleable\"\u003e\u003cinput class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" \u003e\u003clabel for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\"\u003eestimator: NeuralNetClassifier\u003c/label\u003e\u003cdiv class=\"sk-toggleable__content\"\u003e\u003cpre\u003e\u0026lt;class \u0026#x27;skorch.classifier.NeuralNetClassifier\u0026#x27;\u0026gt;[uninitialized](\n","  module=MLP(\n","    (flatten): Flatten(start_dim=1, end_dim=-1)\n","    (input_layer): Linear(in_features=784, out_features=128, bias=True)\n","    (relu): ReLU()\n","    (hidden_layers): ModuleList(\n","      (0-9): 10 x Linear(in_features=128, out_features=128, bias=True)\n","    )\n","    (output_layer): Linear(in_features=128, out_features=10, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  ),\n",")\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"sk-serial\"\u003e\u003cdiv class=\"sk-item\"\u003e\u003cdiv class=\"sk-estimator sk-toggleable\"\u003e\u003cinput class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" \u003e\u003clabel for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\"\u003eNeuralNetClassifier\u003c/label\u003e\u003cdiv class=\"sk-toggleable__content\"\u003e\u003cpre\u003e\u0026lt;class \u0026#x27;skorch.classifier.NeuralNetClassifier\u0026#x27;\u0026gt;[uninitialized](\n","  module=MLP(\n","    (flatten): Flatten(start_dim=1, end_dim=-1)\n","    (input_layer): Linear(in_features=784, out_features=128, bias=True)\n","    (relu): ReLU()\n","    (hidden_layers): ModuleList(\n","      (0-9): 10 x Linear(in_features=128, out_features=128, bias=True)\n","    )\n","    (output_layer): Linear(in_features=128, out_features=10, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  ),\n",")\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e"],"text/plain":["GridSearchCV(cv=3,\n","             estimator=\u003cclass 'skorch.classifier.NeuralNetClassifier'\u003e[uninitialized](\n","  module=MLP(\n","    (flatten): Flatten(start_dim=1, end_dim=-1)\n","    (input_layer): Linear(in_features=784, out_features=128, bias=True)\n","    (relu): ReLU()\n","    (hidden_layers): ModuleList(\n","      (0-9): 10 x Linear(in_features=128, out_features=128, bias=True)\n","    )\n","    (output_layer): Linear(in_features=128, out_features=10, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  ),\n","),\n","             param_grid={'lr': [0.0001, 0.001], 'max_epochs': [50],\n","                         'module__num_layers': [3, 5],\n","                         'module__num_units': [128, 256]},\n","             verbose=2)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# Define hyperparameters for grid search\n","params = {\n","    \"lr\": [0.0001, 0.001],\n","    \"module__num_layers\": [3, 5],\n","    \"module__num_units\": [128, 256],\n","    \"max_epochs\": [50],\n","}\n","\n","grid_search = GridSearchCV(estimator=model, param_grid=params, cv=3, verbose=2)\n","grid_search.fit(X_train, y_train)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HfQD2mdBzFwO"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'lr': 0.0001, 'max_epochs': 50, 'module__num_layers': 5, 'module__num_units': 256}\n"]}],"source":["best_params = grid_search.best_params_\n","print(\"Best hyperparameters:\", best_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nxFcKTfhzFwP"},"outputs":[],"source":["# Find the model with the best parameters\n","best_model = grid_search.best_estimator_"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mu7WUKpPzFwP"},"outputs":[{"name":"stdout","output_type":"stream","text":["Re-initializing module because the following parameters were re-set: num_layers, num_units.\n","Re-initializing criterion.\n","Re-initializing optimizer.\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.1124\u001b[0m       \u001b[32m0.5838\u001b[0m        \u001b[35m1.1552\u001b[0m  6.2696\n","      2        \u001b[36m0.9383\u001b[0m       \u001b[32m0.8898\u001b[0m        \u001b[35m0.4071\u001b[0m  6.6761\n","      3        \u001b[36m0.5178\u001b[0m       \u001b[32m0.9348\u001b[0m        \u001b[35m0.2550\u001b[0m  6.1313\n","      4        \u001b[36m0.3504\u001b[0m       \u001b[32m0.9487\u001b[0m        \u001b[35m0.2122\u001b[0m  6.8096\n","      5        \u001b[36m0.2635\u001b[0m       \u001b[32m0.9557\u001b[0m        \u001b[35m0.1862\u001b[0m  6.2095\n","      6        \u001b[36m0.2176\u001b[0m       \u001b[32m0.9582\u001b[0m        \u001b[35m0.1775\u001b[0m  6.8460\n","      7        \u001b[36m0.1914\u001b[0m       \u001b[32m0.9624\u001b[0m        \u001b[35m0.1616\u001b[0m  6.2218\n","      8        \u001b[36m0.1663\u001b[0m       \u001b[32m0.9634\u001b[0m        \u001b[35m0.1505\u001b[0m  6.8586\n","      9        \u001b[36m0.1438\u001b[0m       \u001b[32m0.9651\u001b[0m        0.1611  6.2918\n","     10        \u001b[36m0.1261\u001b[0m       \u001b[32m0.9683\u001b[0m        \u001b[35m0.1447\u001b[0m  6.8320\n","     11        \u001b[36m0.1140\u001b[0m       0.9680        0.1454  6.8983\n","     12        \u001b[36m0.1040\u001b[0m       \u001b[32m0.9699\u001b[0m        \u001b[35m0.1392\u001b[0m  6.2754\n","     13        \u001b[36m0.0943\u001b[0m       0.9696        0.1500  6.9396\n","     14        \u001b[36m0.0841\u001b[0m       \u001b[32m0.9704\u001b[0m        0.1441  6.3325\n","     15        \u001b[36m0.0771\u001b[0m       \u001b[32m0.9722\u001b[0m        \u001b[35m0.1350\u001b[0m  6.9970\n","     16        \u001b[36m0.0706\u001b[0m       0.9716        0.1470  6.3449\n","     17        \u001b[36m0.0657\u001b[0m       0.9712        0.1429  7.0066\n","     18        \u001b[36m0.0590\u001b[0m       \u001b[32m0.9724\u001b[0m        0.1595  6.8569\n","     19        \u001b[36m0.0557\u001b[0m       \u001b[32m0.9728\u001b[0m        0.1473  6.7117\n","     20        \u001b[36m0.0524\u001b[0m       0.9728        0.1548  7.1366\n","     21        \u001b[36m0.0511\u001b[0m       0.9720        0.1497  6.4936\n","     22        \u001b[36m0.0499\u001b[0m       \u001b[32m0.9737\u001b[0m        0.1459  7.2445\n","     23        \u001b[36m0.0409\u001b[0m       \u001b[32m0.9747\u001b[0m        0.1495  6.4679\n","     24        \u001b[36m0.0374\u001b[0m       0.9744        0.1601  7.1485\n","     25        0.0385       0.9720        0.1718  7.2037\n","     26        0.0377       0.9747        0.1450  6.5887\n","     27        \u001b[36m0.0353\u001b[0m       0.9740        0.1746  7.2056\n","     28        \u001b[36m0.0326\u001b[0m       0.9738        0.1714  6.6141\n","     29        \u001b[36m0.0306\u001b[0m       0.9740        0.1678  7.2834\n","     30        \u001b[36m0.0261\u001b[0m       0.9731        0.1855  7.1589\n","     31        0.0309       \u001b[32m0.9754\u001b[0m        0.1577  7.0146\n","     32        0.0311       0.9747        0.1759  7.3757\n","     33        0.0273       \u001b[32m0.9764\u001b[0m        0.1662  6.8318\n","     34        0.0276       0.9756        0.1630  7.4162\n","     35        0.0262       0.9745        0.1768  7.3123\n","     36        \u001b[36m0.0244\u001b[0m       0.9759        0.1720  7.0724\n","     37        \u001b[36m0.0223\u001b[0m       0.9755        0.1903  7.7256\n","     38        0.0242       \u001b[32m0.9773\u001b[0m        0.1908  6.9797\n","     39        \u001b[36m0.0194\u001b[0m       0.9743        0.1930  7.7988\n","     40        0.0206       0.9748        0.1965  7.7031\n","     41        0.0203       0.9752        0.1783  7.0371\n","     42        \u001b[36m0.0190\u001b[0m       0.9762        0.1855  7.7199\n","     43        \u001b[36m0.0189\u001b[0m       0.9737        0.1979  7.8372\n","     44        0.0197       0.9760        0.1879  7.2997\n","     45        0.0191       0.9752        0.1928  7.8732\n","     46        0.0201       0.9758        0.1918  7.6399\n","     47        \u001b[36m0.0155\u001b[0m       0.9758        0.1967  7.5990\n","     48        0.0191       0.9745        0.1803  7.8556\n","     49        0.0177       0.9752        0.1904  7.5517\n","     50        0.0161       0.9752        0.2045  7.9155\n"]},{"data":{"text/plain":["\u003cclass 'skorch.classifier.NeuralNetClassifier'\u003e[initialized](\n","  module_=MLP(\n","    (flatten): Flatten(start_dim=1, end_dim=-1)\n","    (input_layer): Linear(in_features=784, out_features=256, bias=True)\n","    (relu): ReLU()\n","    (hidden_layers): ModuleList(\n","      (0-4): 5 x Linear(in_features=256, out_features=256, bias=True)\n","    )\n","    (output_layer): Linear(in_features=256, out_features=10, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  ),\n",")"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["best_model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2pKHulUhzFwP"},"outputs":[{"data":{"text/plain":["0.9788"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["best_model.score(X_test, y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ojbUZsROzFwQ"},"outputs":[],"source":["# TODO: Load another dataset of your choice."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"T9H8DTcazFwQ"},"outputs":[],"source":["# TODO: Reimplement the MLP class to work with the new dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"v4IYCnFJzFwQ"},"outputs":[],"source":["# TODO: Wrap the MLP into a scikit-learn classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8kSg7_a8zFwQ"},"outputs":[],"source":["# TODO: Perform grid search to find the best hyperparameters."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PNGQfd9uzFwQ"},"outputs":[],"source":["# TODO: Train and evaluate the MLP on the new dataset using the best hyperparameters."]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"py39","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}