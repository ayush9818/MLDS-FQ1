{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function called `count_words_basic` that takes in the test phrase and returns a dictionary of word counts.\n",
    "\n",
    "**Output:**\n",
    "\n",
    "`{'i': 1,\n",
    " 'bought': 1,\n",
    " 'a': 2,\n",
    " 'sandwich': 1,\n",
    " 'with': 1,\n",
    " 'side': 1,\n",
    " 'of': 1,\n",
    " 'chips': 1}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrase_basic = 'i bought a sandwich with a side of chips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer\n",
      "{'i': 1, 'bought': 1, 'a': 2, 'sandwich': 1, 'with': 1, 'side': 1, 'of': 1, 'chips': 1}\n"
     ]
    }
   ],
   "source": [
    "def count_words_basic(text):\n",
    "    \"\"\"\n",
    "    Takes input a string and returns dictionary of the word count\n",
    "    args:\n",
    "        text : input str\n",
    "    output:\n",
    "        ans_dict: dictionary of word count of text \n",
    "    \"\"\"\n",
    "    ans_dict = {}\n",
    "    # Splitting text into words and looping over each word to generate a count dictionary\n",
    "    for word in text.split(' '):\n",
    "        if word not in ans_dict:\n",
    "            ans_dict[word] = 0\n",
    "        ans_dict[word]+=1\n",
    "    return ans_dict\n",
    "\n",
    "ans_dict = {'i': 1,  'bought': 1,  'a': 2,  'sandwich': 1,  'with': 1,  'side': 1,  'of': 1,  'chips': 1}\n",
    "output_dict = count_words_basic(text = test_phrase_basic)\n",
    "\n",
    "assert ans_dict == output_dict, \"Wrong Answer\"\n",
    "print(\"Correct Answer\")\n",
    "print(output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function called `count_words` that takes in the test phrase and returns a dictionary of word counts.\n",
    "  * Step 1: Write a function called `clean_text` that removes a few common punctuation marks (`.,?!'\"`) and makes all the text lowercase.\n",
    "  * Step 2: Write another function called `count_words` that splits a string of text into words and then cleans it using the function `clean_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrase = 'I bought a sandwich with a side of chips!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(word_list):\n",
    "    \"\"\"\n",
    "    The function removes common punctuation marks (\" , ? ! ')  from the input text\n",
    "    args:\n",
    "        word_list : list of input words to be cleaned\n",
    "    output \n",
    "        out_list: list of cleaned words \n",
    "    \"\"\"\n",
    "    # Creating a string with all punctuation marks that are to removed\n",
    "    punctuations = \"\"\",?!'\".[](){}:;\"\"\"\n",
    "    \n",
    "    out_list = []\n",
    "    \n",
    "    # Iterating over each word from the word list\n",
    "    # Removing the punctuation marks using strip function\n",
    "    for word in word_list:\n",
    "        word = word.strip(punctuations).lower()\n",
    "        out_list.append(word)\n",
    "    return out_list\n",
    "    \n",
    "\n",
    "def count_words(text):\n",
    "    \"\"\"\n",
    "    1) Split the input string into words based on space\n",
    "    2) Clean the list of words by removing common punctuation marks and making the text lowercase\n",
    "    Cleans the text \n",
    "    3) count the frequency of each word\n",
    "    args:\n",
    "        text : input text \n",
    "    output:\n",
    "        count_dict : dictionary of count of words\n",
    "    \"\"\"\n",
    "    \n",
    "    # Splitting the cleaned text into words\n",
    "    word_list = text.split(' ')\n",
    "    # Cleans the text using clean_text function\n",
    "    cleaned_word_list = clean_text(word_list)\n",
    "    \n",
    "    #  get freq count of each word\n",
    "    count_dict = {}\n",
    "    for word in cleaned_word_list:\n",
    "        if word not in count_dict:\n",
    "            count_dict[word] = 0\n",
    "        count_dict[word]+=1\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 1,\n",
       " 'bought': 1,\n",
       " 'a': 2,\n",
       " 'sandwich': 1,\n",
       " 'with': 1,\n",
       " 'side': 1,\n",
       " 'of': 1,\n",
       " 'chips': 1}"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(test_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function called `most_common` that returns the most common word from a string. Explain what the code is actually doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrase = 'I bought a sandwich with a side of chips!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(text):\n",
    "    \"\"\"\n",
    "    1) Given an input text, the function cleans the text by converting into lower text\n",
    "       and removing punctuations.\n",
    "    2) Creates a frequency map of the words\n",
    "    3) Find the most common word from frequency map (highest frequency word)\n",
    "    args:\n",
    "        text : input string\n",
    "    output:\n",
    "        most_common_word : highest frequency word from the text \n",
    "    \"\"\"\n",
    "    # Text cleaning and freq map generation\n",
    "    count_dict = count_words(text)\n",
    "    \n",
    "    # Get highest frequency word from freq map\n",
    "    most_common_word = max(count_dict, key = lambda x : count_dict[x])\n",
    "    \n",
    "    print(f\"Highest Frequency Word : {most_common_word} Frequency : {count_dict[most_common_word]}\")\n",
    "    return most_common_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Frequency Word : a Frequency : 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common(text = test_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function called `count_words_from_file` that allows you to read in a file, clean the text, count the words and return the most common word.\n",
    "\n",
    "**Reminder:** For this homework assignment, there should not be use of any external libraries, so no using pandas.\n",
    "\n",
    "**Hint:** Also remove the `\\n` character in your `clean_text` step, which means \"new line\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"peter_pan_chapter_1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_from_file(file_name):\n",
    "    \"\"\"\n",
    "    a) The function reads the document from a file\n",
    "    b) Cleans the text by converting into lowercase and removing punnctuations\n",
    "    c) Creates a dictionary of word counts\n",
    "    d) Get the m\n",
    "    \"\"\"\n",
    "    # Reading the file using open and reading the contents of the file\n",
    "    with open(file_name, 'r') as file:\n",
    "        data = file.read()\n",
    "        \n",
    "    # Replacing new line with blank space\n",
    "    data = data.replace('\\n', ' ')\n",
    "    \n",
    "    # Generating Freq map of the words after data cleaning using count_words method\n",
    "    count_dict = count_words(data)\n",
    "    \n",
    "    # Finding word with highest frequency from the count dict \n",
    "    most_common_word = max(count_dict, key = lambda x : count_dict[x])\n",
    "    print(f\"Most Common Word : {most_common_word} Frequency : {count_dict[most_common_word]}\")\n",
    "    return most_common_word, count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Word : the Frequency : 135\n"
     ]
    }
   ],
   "source": [
    "most_common_word, count_dict = count_words_from_file(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand on the previous functions to create a function called `count_words_in_many_documents` that reads in a list of documents, and creates a dictionary of word counts across all the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = ['I enjoyed a delicious homemade lasagna for dinner last night.',\n",
    "            'She ordered a classic Caesar salad for lunch at the restaurant.',\n",
    "            'Breakfast is my favorite meal of the day! I always start with a hearty omelette.',\n",
    "            \"We're having grilled chicken with roasted vegetables for tonight's meal.\",\n",
    "            'On a hot summer day, nothing beats a refreshing fruit salad.',\n",
    "            'They decided to order takeout sushi for a convenient and tasty meal.',\n",
    "            'Thanksgiving dinner is traditionally a feast of turkey, stuffing, and cranberry sauce.',\n",
    "            \"My grandmother's homemade apple pie is the perfect dessert to end any meal.\",\n",
    "            \"Aromatic spices and herbs can transform a simple dish into a culinary masterpiece.\",\n",
    "            \"Exploring street food markets in foreign cities is a delightful way to experience local culture.\",\n",
    "            \"The rich and creamy texture of a perfectly ripe avocado is a true gastronomic pleasure.\",\n",
    "            \"Sushi, with its delicate balance of flavors and textures, is an art form on a plate.\",\n",
    "            \"Homemade apple pie, fresh out of the oven, fills the air with a comforting, cinnamon-infused aroma.\",\n",
    "            \"Savoring a warm bowl of chicken soup on a chilly day is like a hug for the soul.\",\n",
    "            \"Food brings people together, creating lasting memories around the dinner table.\",\n",
    "            \"Discovering new flavors and cuisines is an exciting culinary adventure that broadens the palate.\",\n",
    "            \"Grilling outdoors on a sunny day creates a mouthwatering symphony of sizzling meats and vegetables.\",\n",
    "            \"The joy of sharing a delicious meal with loved ones is one of life's simple pleasures.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_freq_map(final_freq_map, temp_freq_map):\n",
    "    \"\"\"\n",
    "    The function updates the final frequecy map using the temporary freq map\n",
    "    args:\n",
    "        final_freq_map: output freq map which needs to be updated \n",
    "        temp_freq_map: temporary freq map which updates the final map \n",
    "    returns:\n",
    "        final_freq_map: updated freq map\n",
    "    \"\"\"\n",
    "    for key, value in temp_freq_map.items():\n",
    "        if key in final_freq_map:\n",
    "            final_freq_map[key]+=value\n",
    "        else:\n",
    "            final_freq_map[key] = value\n",
    "    return final_freq_map\n",
    "\n",
    "\n",
    "def count_words_in_many_documents(documents):\n",
    "    \"\"\"\n",
    "    Given a list of documents, the function performs following operations\n",
    "        a) Cleans each text document by making them lowercase and removing punctuations\n",
    "        b) Creates a individual frequency map for each document \n",
    "        c) Combines all the individual frequency maps\n",
    "    args:\n",
    "        documents : list of input documents\n",
    "    returns:\n",
    "        final_count_dict : combined frequency map of all the documents\n",
    "    \"\"\"\n",
    "    final_count_dict = {}\n",
    "    for document in documents:\n",
    "        \n",
    "        # Getting word count dict for each document \n",
    "        temp_count_dict = count_words(document)\n",
    "        \n",
    "        # Merging temp word count dict into final word count dict \n",
    "        final_count_dict = update_freq_map(final_count_dict, temp_count_dict)\n",
    "    \n",
    "    return final_count_dict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 2, 'enjoyed': 1, 'a': 20, 'delicious': 2, 'homemade': 3, 'lasagna': 1, 'for': 5, 'dinner': 3, 'last': 1, 'night': 1, 'she': 1, 'ordered': 1, 'classic': 1, 'caesar': 1, 'salad': 2, 'lunch': 1, 'at': 1, 'the': 10, 'restaurant': 1, 'breakfast': 1, 'is': 9, 'my': 2, 'favorite': 1, 'meal': 5, 'of': 9, 'day': 4, 'always': 1, 'start': 1, 'with': 5, 'hearty': 1, 'omelette': 1, \"we're\": 1, 'having': 1, 'grilled': 1, 'chicken': 2, 'roasted': 1, 'vegetables': 2, \"tonight's\": 1, 'on': 4, 'hot': 1, 'summer': 1, 'nothing': 1, 'beats': 1, 'refreshing': 1, 'fruit': 1, 'they': 1, 'decided': 1, 'to': 3, 'order': 1, 'takeout': 1, 'sushi': 2, 'convenient': 1, 'and': 7, 'tasty': 1, 'thanksgiving': 1, 'traditionally': 1, 'feast': 1, 'turkey': 1, 'stuffing': 1, 'cranberry': 1, 'sauce': 1, \"grandmother's\": 1, 'apple': 2, 'pie': 2, 'perfect': 1, 'dessert': 1, 'end': 1, 'any': 1, 'aromatic': 1, 'spices': 1, 'herbs': 1, 'can': 1, 'transform': 1, 'simple': 2, 'dish': 1, 'into': 1, 'culinary': 2, 'masterpiece': 1, 'exploring': 1, 'street': 1, 'food': 2, 'markets': 1, 'in': 1, 'foreign': 1, 'cities': 1, 'delightful': 1, 'way': 1, 'experience': 1, 'local': 1, 'culture': 1, 'rich': 1, 'creamy': 1, 'texture': 1, 'perfectly': 1, 'ripe': 1, 'avocado': 1, 'true': 1, 'gastronomic': 1, 'pleasure': 1, 'its': 1, 'delicate': 1, 'balance': 1, 'flavors': 2, 'textures': 1, 'an': 2, 'art': 1, 'form': 1, 'plate': 1, 'fresh': 1, 'out': 1, 'oven': 1, 'fills': 1, 'air': 1, 'comforting': 1, 'cinnamon-infused': 1, 'aroma': 1, 'savoring': 1, 'warm': 1, 'bowl': 1, 'soup': 1, 'chilly': 1, 'like': 1, 'hug': 1, 'soul': 1, 'brings': 1, 'people': 1, 'together': 1, 'creating': 1, 'lasting': 1, 'memories': 1, 'around': 1, 'table': 1, 'discovering': 1, 'new': 1, 'cuisines': 1, 'exciting': 1, 'adventure': 1, 'that': 1, 'broadens': 1, 'palate': 1, 'grilling': 1, 'outdoors': 1, 'sunny': 1, 'creates': 1, 'mouthwatering': 1, 'symphony': 1, 'sizzling': 1, 'meats': 1, 'joy': 1, 'sharing': 1, 'loved': 1, 'ones': 1, 'one': 1, \"life's\": 1, 'pleasures': 1}\n"
     ]
    }
   ],
   "source": [
    "doc_word_dict = count_words_in_many_documents(documents)\n",
    "print(doc_word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function called `return_top_n_words` that takes in a dictionary of word counts (output of previous question) and returns the top n words specified by the user. The default value of n should be 3 if the user doesn't specify in a value.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "`return_top_n_words(docs, n=5)`\n",
    "\n",
    "**Output:**\n",
    "\n",
    "`The word 'a' appears 20 times.\n",
    "The word 'the' appears 10 times.\n",
    "The word 'is' appears 9 times.\n",
    "The word 'of' appears 9 times.\n",
    "The word 'and' appears 7 times.\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_top_n_words(docs, n=5):\n",
    "    \"\"\"\n",
    "    Given a list of document and value of n, the function parses top n words from the document \n",
    "    The function uses the count_words_in_many_documents function to create the freq map of all the documents\n",
    "    args:\n",
    "        docs : list of input documents\n",
    "        n : numbers of top freq words to be returned\n",
    "    output:\n",
    "        top_n_words_dict: dictionary of top n words along with freq\n",
    "    \"\"\"\n",
    "    # Generating word dict from document \n",
    "    doc_word_dict = count_words_in_many_documents(docs)\n",
    "    \n",
    "    if n > len(doc_word_dict):\n",
    "        print(f\"n value exceeds the length of the word count dictionary, n = {n} , len = {len(doc_word_dict)}\")\n",
    "        print(f\"Using n as maximum length of the word count dictionary\")\n",
    "        n = len(doc_word_dict)\n",
    "    \n",
    "    # Sorting the dictionary based on frequency values of the dictionary and getting top n values\n",
    "    top_n_matches = sorted(zip(doc_word_dict.values(), doc_word_dict.keys()), reverse=True)[:n]\n",
    "    \n",
    "    top_n_words_dict = {match[1] : match[0] for match in top_n_matches}\n",
    "    return top_n_words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 20, 'the': 10, 'of': 9, 'is': 9, 'and': 7, 'with': 5, 'meal': 5, 'for': 5, 'on': 4, 'day': 4}\n"
     ]
    }
   ],
   "source": [
    "print(return_top_n_words(documents, n = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
